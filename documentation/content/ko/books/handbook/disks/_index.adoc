---
description: '이 장에서는 FreeBSD에서 디스크와 저장 매체의 사용에 대해 다룹니다. 여기에는 SCSI 및 IDE 디스크, CD 및 DVD 미디어, 메모리 지원 디스크, USB 저장 장치가 포함됩니다.'
next: books/handbook/geom
part: '파트 III. 시스템 관리'
path: /books/handbook/
prev: books/handbook/audit
showBookMenu: 'true'
tags: ["storage", "disks", "gpart", "mount", "quotas", "encrypt", "GPT", "cdrecord", "NTFS", "quotas", "swap", "HAST", "CD", "DVD", "resizing", "growing"]
title: '19장. 스토리지'
weight: 23
---

[[disks]]
= 스토리지
:doctype: book
:toc: macro
:toclevels: 1
:icons: font
:sectnums:
:sectnumlevels: 6
:sectnumoffset: 19
:partnums:
:source-highlighter: rouge
:experimental:
:images-path: books/handbook/disks/

ifdef::env-beastie[]
ifdef::backend-html5[]
:imagesdir: ../../../../images/{images-path}
endif::[]
ifndef::book[]
include::shared/authors.adoc[]
include::shared/mirrors.adoc[]
include::shared/releases.adoc[]
include::shared/attributes/attributes-{{% lang %}}.adoc[]
include::shared/{{% lang %}}/teams.adoc[]
include::shared/{{% lang %}}/mailing-lists.adoc[]
include::shared/{{% lang %}}/urls.adoc[]
toc::[]
endif::[]
ifdef::backend-pdf,backend-epub3[]
include::../../../../../shared/asciidoctor.adoc[]
endif::[]
endif::[]

ifndef::env-beastie[]
toc::[]
include::../../../../../shared/asciidoctor.adoc[]
endif::[]

[[disks-synopsis]]
== 요약

이 장에서는 FreeBSD에서 디스크와 저장 매체의 사용에 대해 다룹니다. 여기에는 SCSI 및 IDE 디스크, CD 및 DVD 미디어, 메모리 지원 디스크, USB 저장 장치가 포함됩니다.

이 장을 읽고 나면 다음을 알 수 있습니다:

* FreeBSD 시스템에 하드디스크를 추가하는 방법.
* FreeBSD에서 디스크 파티션의 크기를 늘리는 방법.
* USB 저장 장치를 사용하도록 FreeBSD를 구성하는 방법.
* FreeBSD 시스템에서 CD 및 DVD 미디어를 사용하는 방법.
* FreeBSD에서 제공되는 백업 프로그램을 사용하는 방법.
* 메모리 디스크를 설정하는 방법.
* 파일 시스템 스냅샷의 정의와 효율적인 사용 방법.
* 할당량을 사용하여 디스크 공간 사용량을 제한하는 방법.
* 디스크를 암호화하고 스왑하여 공격자로부터 보호하는 방법.
* 고가용성 스토리지 네트워크를 구성하는 방법.

이 챕터를 읽기 전에 알아두어야 할 사항입니다:

* crossref:kernelconfig[kernelconfig,configure and install a new FreeBSD kernel] 방법을 알아야 합니다.

[[disks-adding]]
== 디스크 추가하기

이 섹션에서는 현재 드라이브가 하나만 있는 컴퓨터에 새 SATA 디스크를 추가하는 방법을 설명합니다. 먼저 컴퓨터를 끄고 컴퓨터, 컨트롤러 및 드라이브 제조업체의 지침에 따라 컴퓨터에 드라이브를 설치합니다. 시스템을 재부팅하고 `root` 가 됩니다.

[.filename]#/var/run/dmesg.boot# 를 검사하여 새 디스크가 발견되었는지 확인합니다. 이 예제에서는 새로 추가된 SATA 드라이브가 [.filename]#ada1# 으로 표시됩니다.

이 예에서는 새 디스크에 하나의 큰 파티션이 만들어집니다. 더 오래되고 활용도가 낮은 MBR 스키마 대신, http://en.wikipedia.org/wiki/GUID_Partition_Table[GPT] 파티션 스키마를 우선적으로 사용할 것입니다.

[NOTE]
====
추가할 디스크가 비어있지 않으면 `gpart delete` 로 이전 파티션 정보를 제거할 수 있습니다. 자세한 내용은 man:gpart[8]를 참고하세요.
====

파티션 스키마가 생성된 다음 단일 파티션이 추가됩니다. 하드웨어 블록 크기가 더 큰 최신 디스크에서 성능을 향상시키기 위해 파티션은 1메가바이트 경계에 맞춰 정렬됩니다:

[source, shell]
....
# gpart create -s GPT ada1
# gpart add -t freebsd-ufs -a 1M ada1
....

용도에 따라 여러 개의 작은 파티션이 필요할 수 있습니다. 전체 디스크보다 작은 파티션을 만드는 옵션은 man:gpart[8]를 참조하세요.

디스크 파티션 정보는 `gpart show` 로 확인할 수 있습니다:

[source, shell]
....
% gpart show ada1
=>        34  1465146988  ada1  GPT  (699G)
          34        2014        - free -  (1.0M)
        2048  1465143296     1  freebsd-ufs  (699G)
  1465145344        1678        - free -  (839K)
....

새 디스크의 새 파티션에 파일 시스템이 만들어집니다:

[source, shell]
....
# newfs -U /dev/ada1p1
....

원본 디스크의 파일 시스템에서 새 디스크를 마운트하기 위해, _마운트 포인트_ 로 사용할 빈 디렉터리를 만듭니다:

[source, shell]
....
# mkdir /newdisk
....

마지막으로 [.filename]#/etc/fstab# 에 항목을 추가하여 시작 시 새 디스크가 자동으로 마운트되도록 합니다:

[.programlisting]
....
/dev/ada1p1	/newdisk	ufs	rw	2	2
....

새 디스크는 시스템을 다시 시작하지 않고도 수동으로 마운트할 수 있습니다:

[source, shell]
....
# mount /newdisk
....

[[disks-growing]]
== 디스크 크기 조정 및 크기 늘리기

디스크의 용량은 이미 존재하는 데이터를 변경하지 않고도 증가시킬 수 있습니다. 이는 가상 머신에서 가상 디스크가 너무 작은 것으로 판명되어 확대할 때 주로 발생합니다. 때때로 디스크 이미지가 USB 메모리 스틱에 기록되지만 전체 용량을 사용하지 않는 경우가 있습니다. 여기에서는 늘어난 용량을 활용하기 위해 디스크 콘텐츠의 크기를 조정하거나 _늘리는_ 방법을 설명합니다.

[.filename]#/var/run/dmesg.boot# 을 검사하여 크기를 조정할 디스크의 장치 이름을 확인합니다. 이 예제에서는 시스템에 SATA 디스크가 하나만 있으므로 드라이브가 [.filename]#ada0# 로 표시됩니다.

디스크의 파티션을 나열하여 현재 구성을 확인합니다:

[source, shell]
....
# gpart show ada0
=>      34  83886013  ada0  GPT  (48G) [CORRUPT]
        34       128     1  freebsd-boot  (64k)
       162  79691648     2  freebsd-ufs  (38G)
  79691810   4194236     3  freebsd-swap  (2G)
  83886046         1        - free -  (512B)
....

[NOTE]
====
디스크가 http://en.wikipedia.org/wiki/GUID_Partition_Table[GPT] 파티션 스키마로 포맷된 경우 GPT 백업 파티션 테이블이 더 이상 드라이브의 끝에 있지 않기 때문에 "corrupted"으로 표시될 수 있습니다. `gpart` 로 백업 파티션 테이블을 수정합니다:

[source, shell]
....
# gpart recover ada0
ada0 recovered
....

====

이제 디스크의 추가 공간을 새 파티션에서 사용하거나 기존 파티션을 확장할 수 있습니다:

[source, shell]
....
# gpart show ada0
=>       34  102399933  ada0  GPT  (48G)
         34        128     1  freebsd-boot  (64k)
        162   79691648     2  freebsd-ufs  (38G)
   79691810    4194236     3  freebsd-swap  (2G)
   83886046   18513921        - free -  (8.8G)
....

파티션은 인접한 여유 공간으로만 크기를 조정할 수 있습니다. 여기서 디스크의 마지막 파티션은 스왑 파티션이지만 크기를 조정해야 하는 파티션은 두 번째 파티션입니다. 스왑 파티션은 임시 데이터만 포함하므로 안전하게 마운트 해제하고 삭제한 다음 두 번째 파티션의 크기를 조정한 후 세 번째 파티션을 다시 만들 수 있습니다.

스왑 파티션을 비활성화합니다:

[source, shell]
....
# swapoff /dev/ada0p3
....

`-i` 플래그로 지정된 세 번째 파티션을 _ada0_ 디스크에서 삭제합니다.

[source, shell]
....
# gpart delete -i 3 ada0
ada0p3 deleted
# gpart show ada0
=>       34  102399933  ada0  GPT  (48G)
         34        128     1  freebsd-boot  (64k)
        162   79691648     2  freebsd-ufs  (38G)
   79691810   22708157        - free -  (10G)
....

[WARNING]
====

마운트된 파일 시스템의 파티션 테이블을 수정하면 데이터가 손실될 위험이 있습니다. 라이브 CD-ROM 또는 USB 장치에서 실행하는 동안 마운트되지 않은 파일 시스템에서 다음 단계를 수행하는 것이 가장 좋습니다. 그러나 꼭 필요한 경우 GEOM 안전 기능을 비활성화한 후 마운트된 파일 시스템의 크기를 조정할 수 있습니다:

[source, shell]
....
# sysctl kern.geom.debugflags=16
....

====

파티션 크기를 조정하여 원하는 크기의 스왑 파티션을 다시 만들 수 있는 공간을 남겨 둡니다. 크기를 조정할 파티션은 `-i` 로 지정하고 새로 원하는 크기는 `-s` 로 지정합니다. 선택적으로 파티션 정렬은 `-a` 로 제어합니다. 이것은 파티션의 크기만 수정합니다. 파티션의 파일 시스템은 별도의 단계에서 확장됩니다.

[source, shell]
....
# gpart resize -i 2 -s 47G -a 4k ada0
ada0p2 resized
# gpart show ada0
=>       34  102399933  ada0  GPT  (48G)
         34        128     1  freebsd-boot  (64k)
        162   98566144     2  freebsd-ufs  (47G)
   98566306    3833661        - free -  (1.8G)
....

스왑 파티션을 다시 생성하고 활성화합니다. `-s` 로 크기를 지정하지 않으면 남은 공간이 모두 사용됩니다:

[source, shell]
....
# gpart add -t freebsd-swap -a 4k ada0
ada0p3 added
# gpart show ada0
=>       34  102399933  ada0  GPT  (48G)
         34        128     1  freebsd-boot  (64k)
        162   98566144     2  freebsd-ufs  (47G)
   98566306    3833661     3  freebsd-swap  (1.8G)
# swapon /dev/ada0p3
....

크기가 조정된 파티션의 새 용량을 사용하도록 UFS 파일 시스템을 확장합니다:

[source, shell]
....
# growfs /dev/ada0p2
Device is mounted read-write; resizing will result in temporary write suspension for /.
It's strongly recommended to make a backup before growing the file system.
OK to grow file system on /dev/ada0p2, mounted on /, from 38GB to 47GB? [Yes/No] Yes
super-block backups (for fsck -b #) at:
 80781312, 82063552, 83345792, 84628032, 85910272, 87192512, 88474752,
 89756992, 91039232, 92321472, 93603712, 94885952, 96168192, 97450432
....

파일 시스템이 ZFS인 경우, `-e` 와 함께 `online` 하위 명령을 실행하면 크기 조정이 트리거됩니다:

[source, shell]
....
# zpool online -e zroot /dev/ada0p2
....

이제 파티션과 그 안의 파일 시스템 모두 새로운 디스크 공간을 사용하도록 크기가 조정되었습니다.

[[usb-disks]]
== USB 저장 장치

하드 드라이브, USB 썸드라이브, CD 및 DVD 버너와 같은 많은 외장 스토리지 솔루션은 USB(범용 직렬 버스)를 사용합니다. FreeBSD는 USB 1.x, 2.0 및 3.0 장치를 지원합니다.

[NOTE]
====
USB 3.0 지원은 하스웰(Lynx 포인트) 칩셋을 포함한 일부 하드웨어와 호환되지 않습니다. `failed with error 19` 라는 메시지와 함께 FreeBSD가 부팅되는 경우, 시스템 BIOS에서 xHCI/USB3를 비활성화하세요.
====

USB 저장 장치에 대한 지원은 [.filename]#GENERIC# 커널에 내장되어 있습니다. 사용자 지정 커널의 경우 커널 구성 파일에 다음 줄이 있는지 확인하세요:

[.programlisting]
....
device scbus	# SCSI bus (required for ATA/SCSI)
device da	# Direct Access (disks)
device pass	# Passthrough device (direct ATA/SCSI access)
device uhci	# provides USB 1.x support
device ohci	# provides USB 1.x support
device ehci	# provides USB 2.0 support
device xhci	# provides USB 3.0 support
device usb	# USB Bus (required)
device umass	# Disks/Mass storage - Requires scbus and da
device cd	# needed for CD and DVD burners
....

FreeBSD는 SCSI 서브 시스템을 사용하여 USB 저장 장치에 액세스하는 man:umass[4] 드라이버를 사용합니다. 모든 USB 장치는 시스템에서 SCSI 장치로 간주되므로, USB 장치가 CD나 DVD 버너인 경우 커스텀 커널 구성 파일에 `device atapicam` 을 _포함시키지_ 마세요.

이 섹션의 나머지 부분에서는 USB 저장 장치가 FreeBSD에서 인식되는지 확인하는 방법과 장치를 사용할 수 있도록 구성하는 방법을 설명합니다.

=== 장치 구성

USB 구성을 테스트하려면 USB 장치를 연결합니다. `dmesg` 를 사용하여 드라이브가 시스템 메시지 버퍼에 나타나는지 확인합니다. 다음과 같이 표시되어야 합니다:

[source, shell]
....
umass0: <STECH Simple Drive, class 0/0, rev 2.00/1.04, addr 3> on usbus0
umass0:  SCSI over Bulk-Only; quirks = 0x0100
umass0:4:0:-1: Attached to scbus4
da0 at umass-sim0 bus 0 scbus4 target 0 lun 0
da0: <STECH Simple Drive 1.04> Fixed Direct Access SCSI-4 device
da0: Serial Number WD-WXE508CAN263
da0: 40.000MB/s transfers
da0: 152627MB (312581808 512 byte sectors: 255H 63S/T 19457C)
da0: quirks=0x2<NO_6_BYTE>
....

브랜드, 디바이스 노드( [.filename]#da0# ), 속도, 크기는 디바이스에 따라 달라집니다.

USB 장치는 SCSI 장치로 간주되므로 `camcontrol` 을 사용하여 시스템에 연결된 USB 저장 장치를 나열할 수 있습니다:

[source, shell]
....
# camcontrol devlist
<STECH Simple Drive 1.04>          at scbus4 target 0 lun 0 (pass3,da0)
....

다른 방법으로 `usbconfig` 를 사용하여 장치를 나열할 수 있습니다. 이 명령에 대한 자세한 내용은 man:usbconfig[8]을 참조하세요.

[source, shell]
....
# usbconfig
ugen0.3: <Simple Drive STECH> at usbus0, cfg=0 md=HOST spd=HIGH (480Mbps) pwr=ON (2mA)
....

장치를 포맷하지 않은 경우, <<disks-adding>> 에서 USB 드라이브의 포맷 및 파티션 생성 방법을 참조하세요. 드라이브에 파일 시스템이 함께 제공된 경우, crossref:basics[mount-unmount,“Mounting and Unmounting File Systems”]의 지침에 따라 `root` 로 마운트할 수 있습니다.

[WARNING]
====
아래 설명된 대로 `vfs.usermount` 를 활성화하여 신뢰할 수 없는 사용자가 임의의 미디어를 마운트할 수 있도록 허용하는 것은 보안 관점에서 안전하다고 볼 수 없습니다. 대부분의 파일 시스템은 악성 디바이스로부터 보호하도록 설계되지 않았습니다.
====

일반 사용자로 장치를 마운트할 수 있게 하려면 man:pw[8]을 사용하여 장치의 모든 사용자를 `operator` 그룹의 멤버로 만드는 것이 한 가지 해결책입니다. 그런 다음 [.filename]#/etc/devfs.rules# 에 다음을 추가하여 `operator` 가 장치를 읽고 쓸 수 있는지 확인합니다:

[.programlisting]
....
[localrules=5]
add path 'da*' mode 0660 group operator
....

[NOTE]
====
시스템에 내부 SCSI 디스크도 설치되어 있는 경우 두 번째 줄을 다음과 같이 변경합니다:

[.programlisting]
....
add path 'da[3-9]*' mode 0660 group operator
....

이렇게 하면 처음 세 개의 SCSI 디스크( [.filename]#da0# ~ [.filename]#da2# )가 `operator` 그룹에 속하지 않게 됩니다. _3_ 을 내부 SCSI 디스크의 수로 바꿉니다. 이 파일에 대한 자세한 내용은 man:devfs.rules[5]를 참조하세요.
====

그런 다음 [.filename]#/etc/rc.conf# 에 규칙 집합을 활성화합니다:

[.programlisting]
....
devfs_system_ruleset="localrules"
....

그리고 나서 [.filename]#/etc/sysctl.conf# 에 다음 줄을 추가하여 일반 사용자가 파일 시스템을 마운트할 수 있도록 시스템에 지시합니다:

[.programlisting]
....
vfs.usermount=1
....

이 변수는 다음 재부팅 후에만 적용되므로 지금 `sysctl` 을 사용하여 이 변수를 설정하세요:

[source, shell]
....
# sysctl vfs.usermount=1
vfs.usermount: 0 -> 1
....

마지막 단계는 파일 시스템을 마운트할 디렉터리를 만드는 것입니다. 이 디렉터리는 파일 시스템을 마운트할 사용자가 소유해야 합니다. 이를 위한 한 가지 방법은 'root' 가 해당 사용자가 소유한 하위 디렉터리를 [.filename]#/mnt/username# 으로 만드는 것입니다. 다음 예제에서는 _username_ 을 사용자의 로그인 이름으로 바꾸고 _usergroup_ 을 사용자의 기본 그룹으로 바꿉니다:

[source, shell]
....
# mkdir /mnt/username
# chown username:usergroup /mnt/username
....

USB 썸드라이브가 연결되어 있고 [.filename]#/dev/da0s1# 장치가 표시된다고 가정합니다. 장치가 FAT 파일 시스템으로 포맷된 경우 사용자는 다음을 사용하여 마운트할 수 있습니다:

[source, shell]
....
% mount -t msdosfs -o -m=644,-M=755 /dev/da0s1 /mnt/username
....

장치의 플러그를 뽑기 전에 먼저 마운트를 해제해야 합니다:

[source, shell]
....
% umount /mnt/username
....

장치를 제거한 후 시스템 메시지 버퍼에 다음과 유사한 메시지가 표시됩니다:

[source, shell]
....
umass0: at uhub3, port 2, addr 3 (disconnected)
da0 at umass-sim0 bus 0 scbus4 target 0 lun 0
da0: <STECH Simple Drive 1.04> s/n WD-WXE508CAN263          detached
(da0:umass-sim0:0:0:0): Periph destroyed
....

=== 이동식 미디어 자동 마운트

USB 장치는 [.filename]#/etc/auto_master# 에서 다음 줄을 주석 처리하면 자동으로 마운트할 수 있습니다:

[source, shell]
....
/media		-media		-nosuid
....

그런 다음 [.filename]#/etc/devd.conf# 에 이 줄을 추가합니다:

[source, shell]
....
notify 100 {
	match "system" "GEOM";
	match "subsystem" "DEV";
	action "/usr/sbin/automount -c";
};
....

man:autofs[5] 및 man:devd[8]가 이미 실행 중이면 구성을 다시 로드합니다:

[source, shell]
....
# service automount restart
# service devd restart
....

man:autofs[5]가 부팅 시 시작되도록 설정하려면 [.filename]#/etc/rc.conf# 에 이 줄을 추가하면 됩니다:

[.programlisting]
....
autofs_enable="YES"
....

man:autofs[5]를 사용하려면 기본적으로 man:devd[8]가 활성화되어 있어야 합니다.

즉시 서비스를 시작하려면:

[source, shell]
....
# service automount start
# service automountd start
# service autounmountd start
# service devd start
....

자동으로 마운트할 수 있는 각 파일 시스템은 [.filename]#/media/# 에 디렉터리로 나타납니다. 디렉터리는 파일 시스템 레이블의 이름을 따서 명명됩니다. 레이블이 없는 경우 디렉터리는 장치 노드의 이름을 따서 명명됩니다.

파일 시스템은 처음 액세스할 때 투명하게 마운트되고 일정 시간 동안 사용하지 않으면 마운트 해제됩니다. 자동 마운트된 드라이브는 수동으로 마운트 해제할 수도 있습니다:

[source, shell]
....
# automount -fu
....

이 메커니즘은 일반적으로 메모리 카드와 USB 메모리 스틱에 사용됩니다. 광학 드라이브나 iSCSILUN을 포함한 모든 블록 장치와 함께 사용할 수 있습니다.

[[creating-cds]]
== CD 미디어 만들기 및 사용하기

CD(컴팩트 디스크) 미디어는 기존 디스크와 차별화되는 여러 가지 기능을 제공합니다. 트랙 간에 헤드를 이동하는 데 지연 없이 연속적으로 읽을 수 있도록 설계되었습니다. CD 미디어에도 트랙이 있지만 이는 디스크의 물리적 특성이 아니라 연속적으로 읽을 수 있는 데이터 섹션을 의미합니다. ISO 9660 파일 시스템은 이러한 차이점을 처리하도록 설계되었습니다.

FreeBSD 포트 컬렉션은 오디오 및 데이터 CD를 굽고 복제하기 위한 여러 유틸리티를 제공합니다. 이 장에서는 몇 가지 명령줄 유틸리티의 사용법을 설명합니다. 그래픽 유틸리티가 있는 CD 굽기 소프트웨어의 경우, package:sysutils/xcdroast[] 또는 package:sysutils/k3b[] 패키지 또는 포트를 설치하는 것을 고려하십시오.

[[atapicam]]
=== 지원되는 장치

[.filename]#GENERIC# 커널은 SCSI, USB, ATAPICD 리더 및 버너를 지원합니다. 사용자 지정 커널을 사용하는 경우 커널 구성 파일에 있어야 하는 옵션은 장치 유형에 따라 다릅니다.

SCSI 버너의 경우 이러한 옵션이 있는지 확인합니다:

[.programlisting]
....
device scbus	# SCSI bus (required for ATA/SCSI)
device da	# Direct Access (disks)
device pass	# Passthrough device (direct ATA/SCSI access)
device cd	# needed for CD and DVD burners
....

USB 버너의 경우 이러한 옵션이 있는지 확인하세요:

[.programlisting]
....
device scbus	# SCSI bus (required for ATA/SCSI)
device da	# Direct Access (disks)
device pass	# Passthrough device (direct ATA/SCSI access)
device cd	# needed for CD and DVD burners
device uhci	# provides USB 1.x support
device ohci	# provides USB 1.x support
device ehci	# provides USB 2.0 support
device xhci	# provides USB 3.0 support
device usb	# USB Bus (required)
device umass	# Disks/Mass storage - Requires scbus and da
....

ATAPI 버너의 경우 이러한 옵션이 있는지 확인하세요:

[.programlisting]
....
device ata	# Legacy ATA/SATA controllers
device scbus	# SCSI bus (required for ATA/SCSI)
device pass	# Passthrough device (direct ATA/SCSI access)
device cd	# needed for CD and DVD burners
....

[NOTE]
====
10.x 이전 FreeBSD 버전에서는 버너가 ATAPI 장치인 경우 커널 구성 파일에 다음 내용이 필요합니다:

[.programlisting]
....
device atapicam
....

또는 [.filename]#/boot/loader.conf# 에 다음 줄을 추가하여 부팅 시 이 드라이버를 로드할 수 있습니다:

[.programlisting]
....
atapicam_load="YES"
....

이 드라이버는 부팅 시에만 로드할 수 있으므로 시스템을 재부팅해야 합니다.
====

FreeBSD가 장치를 인식하는지 확인하려면 `dmesg` 를 실행하고 장치에 대한 항목을 찾습니다. 10.x 이전 시스템에서는 출력 첫 줄의 장치 이름이 [.filename]#cd0# 이 아닌 [.filename]#acd0# 이 됩니다.

[source, shell]
....
% dmesg | grep cd
cd0 at ahcich1 bus 0 scbus1 target 0 lun 0
cd0: <HL-DT-ST DVDRAM GU70N LT20> Removable CD-ROM SCSI-0 device
cd0: Serial Number M3OD3S34152
cd0: 150.000MB/s transfers (SATA 1.x, UDMA6, ATAPI 12bytes, PIO 8192bytes)
cd0: Attempt to query device size failed: NOT READY, Medium not present - tray closed
....

[[cdrecord]]
=== CD 굽기

FreeBSD에서는 `cdrecord` 를 사용하여 CD를 구울 수 있습니다. 이 명령은 package:sysutils/cdrtools[] 패키지 또는 포트와 함께 설치됩니다.

`cdrecord` 에는 많은 옵션이 있지만 기본 사용법은 간단합니다. 레코딩할 ISO 파일의 이름을 지정하고, 시스템에 여러 개의 버너 장치가 있는 경우 사용할 장치의 이름을 지정합니다:

[source, shell]
....
# cdrecord dev=device imagefile.iso
....

버너의 장치 이름을 확인하기 위해 `-scanbus` 를 사용하면 다음과 같은 결과가 나올 수 있습니다:

[source, shell]
....
# cdrecord -scanbus
ProDVD-ProBD-Clone 3.00 (amd64-unknown-freebsd10.0) Copyright (C) 1995-2010 Jörg Schilling
Using libscg version 'schily-0.9'
scsibus0:
        0,0,0     0) 'SEAGATE ' 'ST39236LW       ' '0004' Disk
        0,1,0     1) 'SEAGATE ' 'ST39173W        ' '5958' Disk
        0,2,0     2) *
        0,3,0     3) 'iomega  ' 'jaz 1GB         ' 'J.86' Removable Disk
        0,4,0     4) 'NEC     ' 'CD-ROM DRIVE:466' '1.26' Removable CD-ROM
        0,5,0     5) *
        0,6,0     6) *
        0,7,0     7) *
scsibus1:
        1,0,0   100) *
        1,1,0   101) *
        1,2,0   102) *
        1,3,0   103) *
        1,4,0   104) *
        1,5,0   105) 'YAMAHA  ' 'CRW4260         ' '1.0q' Removable CD-ROM
        1,6,0   106) 'ARTEC   ' 'AM12S           ' '1.06' Scanner
        1,7,0   107) *
....

CD 버너에 대한 항목을 찾아보면 쉼표로 구분된 세 개의 숫자를 `dev` 의 값으로 사용하고 있습니다. 이 경우 Yamaha 버너 장치는 `1,5,0` 이므로 해당 장치를 지정하는 데 적합한 입력은 `dev=1,5,0` 입니다. 이 값을 지정하는 다른 방법과 오디오 트랙 쓰기 및 쓰기 속도 제어에 대한 정보는 `cdrecord` 의 설명서 페이지를 참조하십시오.

또는 다음 명령을 실행하여 버너의 장치 주소를 가져옵니다:

[source, shell]
....
# camcontrol devlist
<MATSHITA CDRW/DVD UJDA740 1.00>   at scbus1 target 0 lun 0 (cd0,pass0)
....

`scbus`, `target` 및 `lun` 에 숫자 값을 사용합니다. 이 예제에서 `1,0,0` 은 사용할 장치 이름입니다.

[[mkisofs]]
=== ISO 파일 시스템에 데이터 쓰기

데이터 CD를 제작하려면, CD의 트랙을 구성할 데이터 파일을 CD에 구울 수 있도록 먼저 준비해야 합니다. FreeBSD에서, package:sysutils/cdrtools[]는 `mkisofs` 를 설치하는데, 이는 UNIX(R) 파일 시스템 내의 디렉토리 트리 이미지인 ISO 9660 파일 시스템을 생성하는 데 사용할 수 있습니다. 가장 간단한 사용법은 생성할 ISO 파일의 이름과 ISO 9660 파일 시스템에 배치할 파일 경로를 지정하는 것입니다:

[source, shell]
....
# mkisofs -o imagefile.iso /path/to/tree
....

이 명령은 지정된 경로의 파일 이름을 표준 ISO 9660 파일 시스템의 제한에 맞는 이름으로 매핑하고 ISO 파일 시스템 표준에 맞지 않는 파일은 제외합니다.

표준에 의해 부과된 제한을 극복하기 위해 여러 가지 옵션을 사용할 수 있습니다. 특히 `-R` 은 UNIX(R) 시스템에 공통적으로 사용되는 Rock Ridge 확장을 활성화하고 `-J` 는 Microsoft(R) 시스템에서 사용되는 Joliet 확장을 활성화합니다.

FreeBSD 시스템에서만 사용하려는 CD의 경우, `-U` 를 사용하여 모든 파일 이름 제한을 비활성화할 수 있습니다. `-R` 과 함께 사용하면 ISO 9660 표준을 위반하더라도 지정된 FreeBSD 트리와 동일한 파일 시스템 이미지를 생성합니다.

일반적으로 사용되는 마지막 옵션은 `-b` 입니다. 이 옵션은 "El Torito" 부팅 가능한 CD를 생성할 때 사용할 부팅 이미지의 위치를 지정하는 데 사용됩니다. 이 옵션은 CD에 기록되는 트리의 맨 위에 있는 부팅 이미지의 경로인 인수를 받습니다. 기본적으로 `mkisofs` 는 "플로피 디스크 에뮬레이션" 모드에서 ISO 이미지를 생성하므로 부팅 이미지의 크기는 정확히 1200, 1440 또는 2880KB가 될 것으로 예상합니다. FreeBSD 배포 미디어에서 사용하는 것과 같은 일부 부트 로더는 에뮬레이션 모드를 사용하지 않습니다. 이 경우 `-no-emul-boot` 를 사용해야 합니다. 따라서 [.filename]#/tmp/myboot# 에 부팅 이미지가 있는 부팅 가능한 FreeBSD 시스템이 [.filename]#/tmp/myboot/boot/cdboot# 에 있는 경우, 이 명령은 [.filename]#/tmp/bootable.iso# 를 생성합니다:

[source, shell]
....
# mkisofs -R -no-emul-boot -b boot/cdboot -o /tmp/bootable.iso /tmp/myboot
....

결과 ISO 이미지는 다음을 사용하여 메모리 디스크로 마운트할 수 있습니다:

[source, shell]
....
# mdconfig -a -t vnode -f /tmp/bootable.iso -u 0
# mount -t cd9660 /dev/md0 /mnt
....

그런 다음 [.filename]#/mnt# 와 [.filename]#/tmp/myboot# 가 동일한지 확인할 수 있습니다.

다른 많은 옵션을 사용하여 `mkisofs` 의 동작을 세부조정할 수 있습니다. 자세한 내용은 man:mkisofs[8]을 참조하세요.

[NOTE]
====
데이터 CD를 `mkisofs` 로 생성한 이미지 파일과 기능적으로 동일한 이미지 파일로 복사할 수 있습니다. 이렇게 하려면 [.filename]#dd# 를 장치 이름과 함께 입력 파일로 사용하고 생성할 ISO의 이름을 출력 파일로 지정합니다:

[source, shell]
....
# dd if=/dev/cd0 of=file.iso bs=2048
....

결과 이미지 파일은 <<cdrecord>> 에 설명된 대로 CD에 구울 수 있습니다.
====

[[mounting-cd]]
=== 데이터 CD 사용

ISO를 CD에 구운 후에는 파일 시스템 유형, CD가 들어 있는 장치 이름, 기존 마운트 지점을 지정하여 마운트할 수 있습니다:

[source, shell]
....
# mount -t cd9660 /dev/cd0 /mnt
....

`mount` 는 파일 시스템이 `ufs` 유형이라고 가정하기 때문에 데이터 CD를 마운트할 때 `-t cd9660` 이 포함되지 않으면 `Incorrect super block` 오류가 발생합니다.

모든 데이터 CD를 이 방법으로 마운트할 수 있지만, 특정 ISO 9660 확장자를 가진 디스크는 이상하게 작동할 수 있습니다. 예를 들어, Joliet 디스크는 모든 파일 이름을 2바이트 유니코드 문자로 저장합니다. 영어가 아닌 일부 문자가 물음표로 표시되는 경우 `-C` 로 로컬 문자 집합을 지정합니다. 자세한 내용은 man:mount_cd9660[8]을 참조하세요.

[NOTE]
====
`-C` 를 사용하여 이 문자 변환을 수행하려면 커널에 [.filename]#cd9660_iconv.ko# 모듈이 로드되어야 합니다. 이 작업은 [.filename]#loader.conf# 에 다음 줄을 추가하여 수행할 수 있습니다:

[.programlisting]
....
cd9660_iconv_load="YES"
....

그리고 나서 머신을 재부팅하거나 `kldload` 를 사용하여 모듈을 직접 로드합니다.
====

데이터 CD를 마운트하려고 할 때 `Device not configured` 이 표시되는 경우가 있습니다. 이는 일반적으로 CD 드라이브가 트레이에 있는 디스크를 감지하지 못했거나 드라이브가 버스에 표시되지 않는다는 의미입니다. CD 드라이브가 미디어를 감지하는 데 몇 초 정도 걸릴 수 있으므로 조금만 기다려주세요.

때때로 버스 재설정에 응답할 시간이 충분하지 않아 SCSICD 드라이브가 누락될 수 있습니다. 이 문제를 해결하기 위해 사용자 지정 커널을 생성하여 기본 SCSI 지연을 늘릴 수 있습니다. 사용자 지정 커널 구성 파일에 다음 옵션을 추가하고 crossref:kernelconfig[kernelconfig-building,“Building and Installing a Custom Kernel”]의 지침에 따라 커널을 다시 빌드합니다:

[.programlisting]
....
options SCSI_DELAY=15000
....

이렇게 하면 부팅하는 동안 SCSI 버스가 15초 동안 일시 중지되어 CD 드라이브가 버스 재설정에 응답할 수 있는 기회를 갖도록 합니다.

[NOTE]
====
ISO 9660 파일 시스템을 만들지 않고도 파일을 CD에 직접 구울 수 있습니다. 이를 원시 데이터(raw data ) CD 굽기라고 하며 일부 사람들은 백업 목적으로 이 작업을 수행합니다.

이 유형의 디스크는 일반 데이터 CD로 마운트할 수 없습니다. 이러한 CD에 구운 데이터를 검색하려면 원시 장치 노드에서 데이터를 읽어야 합니다. 예를 들어, 이 명령은 두 번째 CD 장치에 있는 압축된 tar 파일을 현재 작업 디렉터리로 추출합니다:

[source, shell]
....
# tar xzvf /dev/cd1
....

데이터 CD를 마운트하려면 `mkisofs` 를 사용하여 데이터를 작성해야 합니다.
====

[[duplicating-audiocds]]
=== 오디오 CD 복제하기

오디오 CD를 복제하려면 CD에서 오디오 데이터를 일련의 파일로 추출한 다음 이 파일을 빈 CD에 씁니다.

<<using-cdrecord>> 에서 오디오 CD를 복제하고 굽는 방법을 설명합니다. FreeBSD 버전이 10.0 미만이고 장치가 ATAPI인 경우, <<atapicam>> 의 지침에 따라 `atapicam` 모듈을 먼저 로드해야 합니다.

[[using-cdrecord]]
[.procedure]
.절차: 오디오 CD 복제하기
. package:sysutils/cdrtools[] 패키지 또는 포트는 `cdda2wav` 를 설치합니다. 이 명령은 모든 오디오 트랙을 추출하는 데 사용할 수 있으며, 각 트랙은 현재 작업 디렉터리에 별도의 WAV 파일로 기록됩니다:
+
[source, shell]
....
% cdda2wav -vall -B -Owav
....
+
시스템에 CD 장치가 하나만 있는 경우 장치 이름을 지정할 필요가 없습니다. 장치를 지정하는 방법에 대한 지침과 이 명령에 사용할 수 있는 다른 옵션에 대해 자세히 알아보려면 `cdda2wav` 매뉴얼 페이지를 참조하세요.
. `cdrecord` 를 사용하여 [.filename]#.wav# 파일을 작성합니다:
+
[source, shell]
....
% cdrecord -v dev=2,0 -dao -useinfo  *.wav
....
+
<<cdrecord>> 에서 설명된 대로 _2,0_ 이 적절하게 설정되었는지 확인합니다.

[[creating-dvds]]
== DVD 미디어 만들기 및 사용하기

CD에 비해 DVD는 차세대 광학 미디어 저장 기술입니다. DVD는 어떤 CD보다 더 많은 데이터를 저장할 수 있으며 비디오 퍼블리싱의 표준입니다.

레코딩 가능한 DVD에는 5가지 물리적 레코딩 형식을 정의할 수 있습니다:

* DVD-R: 최초의 DVD 기록 가능 포맷입니다. DVD-R 표준은 http://www.dvdforum.org/forum.shtml[DVD 포럼]에서 정의합니다. 이 형식은 한 번만 기록할 수 있습니다.
* DVD-RW: DVD-R 표준의 재기록 가능 버전입니다. DVD-RW는 약 1000번 다시 쓸 수 있습니다.
* DVD-RAM: 이동식 하드 드라이브로 볼 수 있는 재기록 가능한 형식입니다. 그러나 이 미디어는 일부 DVD 라이터만 DVD-RAM 포맷을 지원하므로 대부분의 DVD-ROM 드라이브 및 DVD-Video 플레이어와 호환되지 않습니다. DVD-RAM 사용에 대한 자세한 내용은 <<creating-dvd-ram>> 을 참조하세요.
* DVD+RW: https://en.wikipedia.org/wiki/DVD%2BRW_Alliance[DVD+RW 얼라이언스]에서 정의한 재기록 가능 포맷입니다. DVD+RW는 약 1000번 다시 쓸 수 있습니다.
* DVD+R: 이 형식은 DVD+RW 형식의 한 번 쓰기 변형입니다.

단일 레이어 기록 가능 DVD는 최대 4,700,000,000바이트를 저장할 수 있으며, 1킬로바이트는 1024바이트이므로 실제로는 4.38GB 또는 4485MB에 해당합니다.

[NOTE]
====
물리적 미디어와 애플리케이션을 구분해야 합니다. 예를 들어, DVD-Video는 DVD-R, DVD+R 또는 DVD-RW와 같은 기록 가능한 DVD 물리적 미디어에 기록할 수 있는 특정 파일 레이아웃입니다. 미디어 유형을 선택하기 전에 버너와 DVD-비디오 플레이어 모두, 고려 중인 미디어와 호환되는지 확인하십시오.
====

=== 구성

DVD 레코딩을 수행하려면 man:growisofs[1]를 사용합니다. 이 명령은 모든 DVD 미디어 유형을 지원하는 package:sysutils/dvd+rw-tools[] 유틸리티의 일부입니다.

이러한 도구는 SCSI 하위 시스템을 사용하여 장치에 액세스하므로 <<atapicam,ATAPI/CAM support>> 이 커널에 로드되거나 정적으로 컴파일되어야 합니다. 버너가 USB 인터페이스를 사용하는 경우 이 지원은 필요하지 않습니다. USB 장치 구성에 대한 자세한 내용은 <<usb-disks>> 를 참조하세요.

DMA는 [.filename]#/boot/loader.conf# 에 다음 줄을 추가하여 ATAPI 장치에 대한 액세스 활성화를 해야 합니다:

[.programlisting]
....
hw.ata.atapi_dma="1"
....

dvd+rw-tools를 사용하기 전에 http://fy.chalmers.se/~appro/linux/DVD+RW/hcn.html[하드웨어 호환성 참고 사항]을 참조하세요.

[NOTE]
====
그래픽 사용자 인터페이스의 경우, man:growisofs[1] 및 기타 여러 굽기 도구에 사용자 친화적인 인터페이스를 제공하는 package:sysutils/k3b[]를 사용하는 것이 좋습니다.
====

=== 데이터 DVD 굽기

man:growisofs[1]는 <<mkisofs,mkisofs>> 에 대한 프런트 엔드이므로, man:mkisofs[8]을 호출하여 파일 시스템 레이아웃을 생성하고 DVD에 쓰기를 수행합니다. 즉, 굽기 프로세스 전에 데이터 이미지를 만들 필요가 없습니다.

[.filename]#/path/to/data# 에 있는 데이터를 DVD+R 또는 DVD-R로 구우려면 다음 명령을 사용합니다:

[source, shell]
....
# growisofs -dvd-compat -Z /dev/cd0 -J -R /path/to/data
....

이 예제에서는 `-J -R` 을 man:mkisofs[8]에 전달하여 Joliet 및 Rock Ridge 확장자를 가진 ISO 9660 파일 시스템을 생성합니다. 자세한 내용은 man:mkisofs[8]을 참조하십시오.

초기 세션 녹화의 경우 단일 세션과 다중 세션 모두에 `-Z` 가 사용됩니다. _/dev/cd0_ 를 DVD 장치의 이름으로 바꿉니다. `-dvd-compat` 을 사용하면 디스크가 닫히고 레코딩을 추가할 수 없음을 나타냅니다. 이렇게 하면 DVD-ROM 드라이브와의 미디어 호환성이 향상됩니다.

_imagefile.iso_ 와 같이 미리 마스터링된 이미지를 구우려면:

[source, shell]
....
# growisofs -dvd-compat -Z /dev/cd0=imagefile.iso
....

쓰기 속도는 사용 중인 미디어와 드라이브에 따라 감지되고 자동으로 설정되어야 합니다. 쓰기 속도를 강제로 설정하려면 `-speed=` 를 사용합니다. 예제 사용법은 man:growisofs[1]을 참조하세요.

[NOTE]
====
4.38GB보다 큰 작업 파일을 지원하려면 `-udf -iso-level 3` 을 man:mkisofs[8] 및 man:growisofs[1]와 같은 모든 관련 프로그램에 전달하여 UDF/ISO-9660 하이브리드 파일 시스템을 만들어야 합니다. 이 옵션은 ISO 이미지 파일을 만들거나 디스크에 직접 파일을 쓸 때만 필요합니다. 이렇게 만든 디스크는 man:mount_udf[8]를 사용하여 UDF 파일 시스템으로 마운트해야 하므로, UDF를 인식하는 운영 체제에서만 사용할 수 있습니다. 그렇지 않으면 손상된 파일이 포함된 것처럼 보입니다.

이 유형의 ISO 파일을 만들려면:

[source, shell]
....
% mkisofs -R -J -udf -iso-level 3 -o imagefile.iso /path/to/data
....

디스크에 직접 파일을 구우려면:

[source, shell]
....
# growisofs -dvd-compat -udf -iso-level 3 -Z /dev/cd0 -J -R /path/to/data
....

ISO 이미지에 이미 대용량 파일이 포함되어 있는 경우, man:growisofs[1]가 해당 이미지를 디스크에 구울 때 추가 옵션이 필요하지 않습니다.

이전 버전에는 대용량 파일을 지원하지 않을 수 있으므로 man:mkisofs[8]가 포함된 최신 버전의 package:sysutils/cdrtools[]를 사용해야 합니다. 최신 버전이 작동하지 않는 경우 package:sysutils/cdrtools-devel[]을 설치하고 man:mkisofs[8]을 읽어보세요.
====

=== DVD-비디오 굽기

DVD-비디오는 ISO 9660 및 micro-UDF (M-UDF) 사양에 기반한 파일 레이아웃입니다. DVD-Video는 특징적인 데이터 구조 계층 구조를 제공하므로 DVD를 제작하려면 package:multimedia/dvdauthor[]와 같은 프로그램이 필요합니다.

DVD-Video 파일 시스템의 이미지가 이미 존재하는 경우 다른 이미지와 동일한 방법으로 구울 수 있습니다. DVD를 만드는 데 `dvdauthor` 를 사용했고 그 결과가 [.filename]#/path/to/video# 에 있는 경우, 다음 명령을 사용하여 DVD-Video를 구워야 합니다:

[source, shell]
....
# growisofs -Z /dev/cd0 -dvd-video /path/to/video
....

`-dvd-video` 는 DVD-Video 파일 시스템 레이아웃을 만들도록 man:mkisofs[8]에 지시하는 옵션입니다. 이 옵션은 `-dvd-compat` man:growisofs[1] 옵션을 뜻합니다.

=== DVD+RW 사용하기

CD-RW와 달리 비어있는 DVD+RW는 처음 사용하기 전에 포맷해야 합니다. 가능하면 man:growisofs[1]가 이 작업을 자동으로 처리하도록 하는 것을 _권장_ 합니다. 그러나 `dvd+rw-format` 을 사용하여 DVD+RW를 포맷할 수 있습니다:

[source, shell]
....
# dvd+rw-format /dev/cd0
....

이 작업은 한 번만 수행하고 비어있는 DVD+RW 미디어만 포맷해야 한다는 점에 유의하세요. 포맷이 완료되면 DVD+RW는 평소와 같이 구울 수 있습니다.

DVD+RW에 일부 데이터를 추가하는 것이 아니라 완전히 새로운 파일 시스템을 구우려면 먼저 미디어를 비울 필요가 없습니다. 다음과 같이 이전 레코딩을 덮어쓰면 됩니다:

[source, shell]
....
# growisofs -Z /dev/cd0 -J -R /path/to/newdata
....

DVD+RW 포맷은 이전 기록에 데이터를 추가하는 기능을 지원합니다. 이 작업은 다중 세션 쓰기로 간주되지 않으므로 새 세션을 기존 세션에 병합하는 것으로 구성됩니다. man:growisofs[1]은 미디어에 있는 ISO 9660 파일 시스템을 _성장_ 시킵니다.

예를 들어 DVD+RW에 데이터를 추가하려면:

[source, shell]
....
# growisofs -M /dev/cd0 -J -R /path/to/nextdata
....

다음 쓰기 시에는 초기 세션을 구울 때 사용한 것과 동일한 man:mkisofs[8] 옵션을 사용해야 합니다.

[NOTE]
====
DVD-ROM 드라이브와의 미디어 호환성을 높이려면 `-dvd-compat` 을 사용하세요. DVD+RW를 사용하는 경우 이 옵션은 데이터 추가를 막지 않습니다.
====

미디어를 비우려면:

[source, shell]
....
# growisofs -Z /dev/cd0=/dev/zero
....

=== DVD-RW 사용하기

DVD-RW는 두 가지 디스크 포맷을 지원합니다: 증분 순차 덮어쓰기와 제한 덮어쓰기입니다. 기본적으로 DVD-RW 디스크는 순차 포맷입니다.

비어있는 DVD-RW는 포맷하지 않고 직접 기록할 수 있습니다. 그러나 순차 포맷이 아닌 공 DVD-RW는 새 초기 세션을 쓰기 전에 한차례 삭제해야 합니다.

순차 모드에서 DVD-RW를 비우려면:

[source, shell]
....
# dvd+rw-format -blank=full /dev/cd0
....

[NOTE]
====
`-blank=full` 를 사용한 전체 블랭크는 1x 미디어에서 약 1시간이 소요됩니다. DVD-RW를 한번에 디스크 기록(DAO) 모드로 기록할 경우 `-blank` 를 사용하여 빠른 삭제를 수행할 수 있습니다. DAO 모드에서 DVD-RW를 구우려면 다음 명령을 사용하십시오:

[source, shell]
....
# growisofs -use-the-force-luke=dao -Z /dev/cd0=imagefile.iso
....

man:growisofs[1]는 자동으로 빠르게 비워진 미디어를 감지하고 DAO 쓰기를 시도하므로 `-use-the-force-luke=dao` 옵션이 필요하지 않습니다.

이 형식은 기본값인 증분 순차보다 유연성이 뛰어나므로 DVD-RW에 제한 덮어쓰기 모드를 사용하는 것이 좋습니다.
====

순차모드로 DVD-RW에 데이터를 기록하려면 다른 DVD 포맷과 동일한 지침을 따르세요:

[source, shell]
....
# growisofs -Z /dev/cd0 -J -R /path/to/data
....

이전 레코딩에 일부 데이터를 추가하려면 `-M` 과 함께 man:growisofs[1]을 사용합니다. 그러나 DVD-RW에 데이터를 증분 순차 모드로 추가하면 디스크에 새 세션이 생성되고 그 결과 멀티 세션 디스크가 됩니다.

제한된 덮어쓰기 형식의 DVD-RW는 새로운 초기 세션 전에 디스크를 비울 필요가 없습니다. 대신 `-Z` 로 디스크를 덮어씁니다. 디스크에 기록된 기존 ISO 9660 파일 시스템을 `-M` 으로 성장시킬 수도 있습니다. 결과적으로 싱글 세션 DVD가 됩니다.

DVD-RW를 제한된 덮어쓰기 포맷으로 설정하려면 다음 명령을 사용해야 합니다:

[source, shell]
....
# dvd+rw-format /dev/cd0
....

순차 형식으로 다시 변경하려면 다음을 사용합니다:

[source, shell]
....
# dvd+rw-format -blank=full /dev/cd0
....

=== 멀티 세션

멀티 세션 DVD를 지원하는 DVD-ROM 드라이브는 거의 없으며 대부분의 경우 첫 번째 세션만 읽습니다. 순차 형식의 DVD+R, DVD-R 및 DVD-RW는 여러 세션을 수용할 수 있습니다. DVD+RW 및 덮어쓰기 제한 형식의 DVD-RW에는 다중 세션이라는 개념이 없습니다.

DVD+R, DVD-R 또는 DVD-RW에서 순차적으로 닫히지 않은 초기 세션이 끝난 후 다음 명령을 사용하면 디스크에 새 세션이 추가됩니다:

[source, shell]
....
# growisofs -M /dev/cd0 -J -R /path/to/nextdata
....

이 명령을 제한된 덮어쓰기 모드에서 DVD+RW 또는 DVD-RW와 함께 사용하면 새 세션을 기존 세션에 병합하면서 데이터를 추가할 수 있습니다. 결과는 단일 세션 디스크가 됩니다. 이러한 유형의 미디어에 처음 쓴 후 데이터를 추가하려면 다음 방법을 사용하십시오.

[NOTE]
====
각 세션 사이에는 세션의 끝과 시작을 표시하기 위해 미디어의 일부 공간이 사용되므로 미디어 공간을 최적화하려면 데이터 용량이 큰 세션을 추가해야 합니다. 세션 수는 DVD+R의 경우 154개, DVD-R의 경우 약 2000개, DVD+R 더블 레이어의 경우 127개로 제한됩니다.
====

=== 추가정보

DVD에 대한 자세한 정보를 얻으려면 지정된 드라이브에 디스크가 있는 상태에서 `dvd+rw-mediainfo _/dev/cd0_` 를 사용하세요.

dvd+rw-tools에 대한 자세한 내용은 man:growisofs[1], http://fy.chalmers.se/~appro/linux/DVD+RW/[dvd+rw-tools 웹 사이트] 및 http://lists.debian.org/cdwrite/[cdwrite 메일링 리스트] 아카이브에서 확인할 수 있습니다.

[NOTE]
====
DVD+RW 도구 사용과 관련된 문제 보고서를 작성할 때는 항상 `dvd+rw-mediainfo` 의 출력을 포함하세요.
====

[[creating-dvd-ram]]
=== DVD-RAM 사용하기

DVD-RAM 라이터는 SCSI 또는 ATAPI 인터페이스를 사용할 수 있습니다. ATAPI 장치의 경우 [.filename]#/boot/loader.conf# 에 다음 줄을 추가하여 DMA 액세스를 활성화해야 합니다:

[.programlisting]
....
hw.ata.atapi_dma="1"
....

DVD-RAM은 이동식 하드 드라이브로 볼 수 있습니다. 다른 하드 드라이브와 마찬가지로 DVD-RAM을 사용하려면 먼저 포맷해야 합니다. 이 예에서는 전체 디스크 공간이 표준 UFS2 파일 시스템으로 포맷됩니다:

[source, shell]
....
# dd if=/dev/zero of=/dev/acd0 bs=2k count=1
# bsdlabel -Bw acd0
# newfs /dev/acd0
....

DVD 장치인 [.filename]#acd0# 은 반드시 구성을 이용해 변경해야 합니다.

DVD-RAM을 포맷한 후에는 일반 하드 드라이브처럼 마운트 할 수 있습니다:

[source, shell]
....
# mount /dev/acd0 /mnt
....

마운트가 완료되면 DVD-RAM은 읽기 및 쓰기가 모두 가능합니다.

[[floppies]]
== 플로피 디스크 만들기 및 사용하기

이 섹션에서는 FreeBSD에서 3.5인치 플로피 디스크를 포맷하는 방법을 설명합니다.

[.procedure]
====
*절차: 플로피 포맷 단계*

플로피 디스크를 사용하려면 먼저 로우 레벨 포맷을 해야 합니다. 이 작업은 일반적으로 공급업체에서 수행하지만, 포맷은 미디어 무결성을 확인하는 좋은 방법입니다. FreeBSD에서 플로피 디스크를 로우레벨 포맷하려면 man:fdformat[1]을 사용합니다. 이 유틸리티를 사용할 때는 디스크의 양호 여부를 판단하는 데 도움이 될 수 있으므로 오류 메시지를 기록해 두세요.

. 플로피를 포맷하려면 새 3.5인치 플로피 디스크를 첫 번째 플로피 드라이브에 삽입하고:
+
[source, shell]
....
# /usr/sbin/fdformat -f 1440 /dev/fd0
....
+
. 디스크를 로우레벨 포맷한 후 시스템에서 디스크의 크기와 지오메트리를 결정하는 데 필요한 디스크 레이블을 생성합니다. 지원되는 지오메트리 값은 [.filename]#/etc/disktab# 에 나열됩니다.
+
디스크 레이블을 작성하려면 man:bsdlabel[8]을 사용합니다:
+
[source, shell]
....
# /sbin/bsdlabel -B -w /dev/fd0 fd1440
....
+
. 이제 플로피에 파일 시스템을 사용하여 높은 수준의 포맷을 할 준비가 되었습니다. 플로피의 파일 시스템은 UFS 또는 FAT 중 하나를 선택할 수 있으며, 일반적으로 플로피에는 FAT가 더 좋습니다.
+
FAT로 플로피를 포맷하려면:
+
[source, shell]
....
# /sbin/newfs_msdos /dev/fd0
....
====

이제 디스크를 사용할 준비가 되었습니다. 플로피를 사용하려면 man:mount_msdosfs[8]로 마운트합니다. 포트 컬렉션에서 package:emulators/mtools[]를 설치하여 사용할 수도 있습니다.

[[using-ntfs]]
== NTFS 디스크 사용하기

이 섹션에서는 FreeBSD에서 NTFS 디스크를 마운트하는 방법을 설명합니다.

NTFS (New Technology File System)는 Microsoft(R)에서 개발한 독점적인 저널링 파일 시스템입니다. 수년 동안 마이크로소프트 윈도우(R)의 기본 파일 시스템으로 사용되어 왔습니다. FreeBSD는 FUSE 파일 시스템을 사용하여 NTFS 볼륨을 마운트할 수 있습니다. 이 파일 시스템은 잘 정의된 인터페이스를 통해 man:fusefs[5] 커널 모듈과 상호 작용하는 사용자 공간 프로그램으로 구현됩니다.

[.procedure]
====
*절차: NTFS 디스크를 마운트하는 단계*

. FUSE 파일 시스템을 사용하기 전에 man:fusefs[5] 커널 모듈을 로드해야 합니다:
+
[source, shell]
....
# kldload fusefs
....
+
시작 시 모듈을 로드하려면 man:sysrc[8]를 사용하세요:
+
[source, shell]
....
# sysrc kld_list+=fusefs
....

. 예제에서와 같이 패키지(crossref:ports[pkgng-intro,Using pkg for Binary Package Management] 참조) 또는 포트(crossref:ports[ports-using,Using the Ports Collection] 참조)에서 실제 NTFS 파일 시스템을 설치합니다:
+
[source, shell]
....
# pkg install fusefs-ntfs
....

. 마지막으로 파일 시스템을 마운트할 디렉터리를 만들어야 합니다:
+
[source, shell]
....
# mkdir /mnt/usb
....

. USB 디스크가 연결되어 있다고 가정합니다. 디스크 파티션 정보는 man:gpart[8]로 볼 수 있습니다:
+
[source, shell]
....
# gpart show da0
=>	  63  1953525105  da0 MBR   (932G)
	  63  1953525105    1 ntfs  (932G)
....

. 다음 명령을 사용하여 디스크를 마운트할 수 있습니다:
+
[source, shell]
....
# ntfs-3g /dev/da0s1 /mnt/usb/
....
이제 디스크를 사용할 준비가 되었습니다.
+
. 또한 /etc/fstab에 항목을 추가할 수도 있습니다:
+
[.programlisting]
....
/dev/da0s1  /mnt/usb	ntfs mountprog=/usr/local/bin/ntfs-3g,noauto,rw  0 0
....
+
이제 디스크를 마운트할 수 있습니다:
+
[source, shell]
....
# mount /mnt/usb
....

. 디스크를 마운트 해제할 수 있습니다:
+
[source, shell]
....
# umount /mnt/usb/
....
====

[[backup-basics]]
== 백업의 기초

디스크 장애, 우발적인 파일 삭제, 무작위 파일 손상 또는 온사이트 백업의 파괴를 포함한 완전한 시스템 파괴로부터 복구할 수 있는 능력을 갖추려면 백업 계획을 실행하는 것이 필수적입니다.

백업 유형과 일정은 데이터의 중요도, 파일 복원에 필요한 세부 수준, 허용 가능한 다운타임의 양에 따라 달라집니다. 몇 가지 가능한 백업 기술은 다음과 같습니다:

* 영구적인 오프사이트 미디어에 백업된 전체 시스템 아카이브. 이 방법은 위에 나열된 모든 문제에 대한 보호 기능을 제공하지만, 특히 권한이 없는 사용자의 경우 복원 속도가 느리고 불편합니다.
* 파일 시스템 스냅샷은 삭제된 파일이나 이전 버전의 파일을 복원하는 데 유용합니다.
* 예약된 package:net/rsync[]를 사용하여 네트워크의 다른 시스템과 동기화되는 전체 파일 시스템 또는 디스크의 복사본입니다.
* 디스크 장애 시 다운타임을 최소화하거나 방지하는 하드웨어 또는 소프트웨어 RAID입니다.

일반적으로 여러 백업 기술이 혼합되어 사용됩니다. 예를 들어, 매주 오프사이트에 저장되는 전체 시스템 백업을 자동화하고 이 백업을 시간별 ZFS 스냅샷으로 보완하는 일정을 만들 수 있습니다. 또한 파일을 편집하거나 삭제하기 전에 개별 디렉터리 또는 파일을 수동으로 백업할 수도 있습니다.

이 섹션에서는 FreeBSD 시스템에서 백업을 생성하고 관리하는 데 사용할 수 있는 몇 가지 유틸리티에 대해 설명합니다.

=== 파일 시스템 백업

파일 시스템을 백업하는 전통적인 UNIX(R) 프로그램은 백업을 생성하는 man:dump[8]와 백업을 복원하는 man:restore[8]입니다. 이러한 유틸리티는 파일 시스템에서 생성되는 파일, 링크 및 디렉터리의 추상화 아래인 디스크 블록 수준에서 작동합니다. 다른 백업 소프트웨어와 달리 `dump` 는 전체 파일 시스템을 백업하며 파일 시스템의 일부만 백업하거나 여러 파일 시스템에 걸쳐 있는 디렉토리 트리를 백업할 수 없습니다. `dump` 는 파일과 디렉터리를 쓰는 대신 파일과 디렉터리를 구성하는 원시 데이터 블록을 기록합니다.

[NOTE]
====
루트 디렉터리에 `dump` 를 사용하면 일반적으로 다른 파일 시스템의 마운트 지점 또는 해당 파일 시스템에 대한 심볼릭 링크로 구성된 [.filename]#/home#, [.filename]#/usr# 또는 다른 대부분의 디렉터리를 백업하지 않습니다.
====

데이터를 복원하는 데 사용하는 경우 `restore` 는 기본적으로 임시 파일을 [.filename]#/tmp/# 에 저장합니다. 작은 [.filename]#/tmp# 의 복구 디스크를 사용하는 경우 복원이 성공하려면 여유 공간이 더 많은 디렉터리로 `TMPDIR` 을 설정하세요.

`dump` 를 사용할 때는 1975년경 AT&T UNIX(R) 버전 6 초기의 몇 가지 특이한 점이 남아 있다는 점에 유의하세요. 기본 매개변수는 다른 유형의 미디어나 현재 사용 가능한 고밀도 테이프가 아닌 9트랙 테이프에 백업한다고 가정합니다. 이러한 기본값은 명령줄에서 재정의해야 합니다.

네트워크를 통해 파일 시스템을 다른 시스템이나 다른 컴퓨터에 연결된 테이프 드라이브에 백업할 수 있습니다. man:rdump[8] 및 man:rrestore[8] 유틸리티를 이 용도로 사용할 수 있지만, 이 유틸리티는 안전하지 않은 것으로 간주됩니다.

대신, `dump` 와 `restore` 을 사용하여 SSH 연결을 통해 보다 안전한 방식으로 백업할 수 있습니다. 이 예에서는 [.filename]#/usr# 의 전체 압축 백업을 만들고 SSH 연결을 통해 지정된 호스트로 백업 파일을 보냅니다.

.ssh에서 `dump` 사용하기
[example]
====
[source, shell]
....
# /sbin/dump -0uan -f - /usr | gzip -2 | ssh -c blowfish \
          targetuser@targetmachine.example.com dd of=/mybigfiles/dump-usr-l0.gz
....
====

이 예에서는 SSH 연결을 통해 원격 시스템의 테이프 드라이브에 백업을 쓰기 위해 `RSH` 를 설정합니다:

.ssh에 `dump` 를 `RSH` 설정으로 사용하기
[example]
====
[source, shell]
....
# env RSH=/usr/bin/ssh /sbin/dump -0uan -f targetuser@targetmachine.example.com:/dev/sa0 /usr
....
====

=== 디렉터리 백업

필요에 따라 지정된 파일과 디렉터리를 백업하고 복원할 수 있는 여러 가지 기본 제공 유틸리티를 사용할 수 있습니다.

디렉터리에 있는 모든 파일을 백업하는 데는 man:tar[1]를 사용하는 것이 좋습니다. 이 유틸리티는 AT&T UNIX(R) 버전 6으로 거슬러 올라가며 기본적으로 로컬 테이프 장치에 대한 재귀 백업을 가정합니다. 스위치를 사용하여 백업 파일의 이름을 대신 지정할 수 있습니다.

이 예에서는 현재 디렉터리의 압축 백업을 만들어 [.filename]#/tmp/mybackup.tgz# 에 저장합니다. 백업 파일을 만들 때 백업이 백업 중인 디렉터리와 동일한 디렉터리에 저장되지 않도록 하세요.

.`tar` 로 현재 디렉토리 백업하기
[example]
====
[source, shell]
....
# tar czvf /tmp/mybackup.tgz .
....
====

전체 백업을 복원하려면 복원할 디렉터리에 `cd` 를 입력하고 백업 이름을 지정합니다. 이렇게 하면 복원 디렉터리에 있는 최신 버전의 파일을 덮어쓰게 됩니다. 확실하지 않은 경우 임시 디렉터리로 복원하거나 복원할 백업 내의 파일 이름을 지정하세요.

.`tar` 로 현재 디렉토리 복원하기
[example]
====
[source, shell]
....
# tar xzvf /tmp/mybackup.tgz
....
====

man:tar[1]에 설명된 수십 가지 스위치를 사용할 수 있습니다. 이 유틸리티는 지정한 디렉터리를 백업하거나 백업에서 파일을 복원할 때 포함하지 말아야 할 파일을 지정하는 제외 패턴 사용도 지원합니다.

지정된 파일 및 디렉터리 목록을 사용하여 백업을 생성하려면 man:cpio[1]를 사용하는 것이 좋습니다. `tar` 와 달리 `cpio` 는 디렉토리 트리를 탐색하는 방법을 모르기 때문에 백업할 파일 목록을 제공해야 합니다.

예를 들어, `ls` 또는 `find` 를 사용하여 파일 목록을 만들 수 있습니다. 이 예에서는 현재 디렉터리의 재귀 목록을 생성한 다음 `cpio` 로 파이프하여 [.filename]#/tmp/mybackup.cpio# 라는 이름의 출력 백업 파일을 생성합니다.

.`ls` 및 `cpio` 를 사용하여 현재 디렉토리의 재귀적 백업 만들기
[example]
====
[source, shell]
....
# ls -R | cpio -ovF /tmp/mybackup.cpio
....
====

`tar` 와 `cpio` 가 제공하는 기능을 연결하는 백업 유틸리티는 man:pax[1]입니다. 수년에 걸쳐, `tar` 와 `cpio` 의 다양한 버전은 약간 호환되지 않게 되었습니다. POSIX(R)는 다양한 `cpio` 와 `tar` 포맷과 새로운 포맷을 읽고 쓰도록 시도하는 `pax` 를 만들었습니다.

이전 예제에 해당하는 'pax' 는 다음과 같습니다:

.`pax` 로 현재 디렉토리 백업하기
[example]
====
[source, shell]
....
# pax -wf /tmp/mybackup.pax .
....
====

[[backups-tapebackups]]
=== 백업에 데이터 테이프 사용하기

테이프 기술은 계속 발전해 왔지만, 최신 백업 시스템은 오프사이트 백업과 로컬 이동식 미디어를 결합하는 경향이 있습니다. FreeBSD는 LTO 또는 DAT와 같은 SCSI를 사용하는 모든 테이프 드라이브를 지원합니다. SATA 및 USB 테이프 드라이브에 대한 지원은 제한적입니다.

SCSI 테이프 장치의 경우, FreeBSD는 man:sa[4] 드라이버와 [.filename]#/dev/sa0#, [.filename]#/dev/nsa0# 및 [.filename]#/dev/esa0# 장치를 사용합니다. 실제 장치 이름은 [.filename]#/dev/sa0# 입니다. [.filename]#/dev/nsa0# 을 사용하면 백업 애플리케이션이 파일 쓰기 후 테이프를 되감지 않으므로 테이프에 두 개 이상의 파일을 쓸 수 있습니다. [.filename]#/dev/esa0# 을 사용하면 장치를 닫은 후 테이프가 배출됩니다.

FreeBSD에서 `mt` 는 테이프에 있는 파일을 찾거나 테이프에 테이프 제어 표시를 쓰는 등 테이프 드라이브의 작업을 제어하는 데 사용됩니다. 예를 들어, 테이프에 있는 처음 세 개의 파일은 새 파일을 쓰기 전에 건너뛰어서 보존할 수 있습니다:

[source, shell]
....
# mt -f /dev/nsa0 fsf 3
....

이 유틸리티는 다양한 작업을 지원합니다. 자세한 내용은 man:mt[1]을 참조하세요.

`tar` 를 사용하여 단일 파일을 테이프에 기록하려면 테이프 장치의 이름과 백업할 파일을 지정합니다:

[source, shell]
....
# tar cvf /dev/sa0 file
....

테이프의 'tar' 아카이브에서 현재 디렉토리로 파일을 복구하려면:

[source, shell]
....
# tar xvf /dev/sa0
....

UFS 파일 시스템을 백업하려면 `dump` 를 사용합니다. 이 예제는 완료되면 테이프를 되감지 않고 [.filename]#/usr# 을 백업합니다:

[source, shell]
....
# dump -0aL -b64 -f /dev/nsa0 /usr
....

테이프의 `dump` 파일에서 현재 디렉토리로 파일을 대화형으로 복원합니다:

[source, shell]
....
# restore -i -f /dev/nsa0
....

[[backups-programs-amanda]]
=== 타사 백업 유틸리티

FreeBSD 포트 컬렉션은 백업 생성을 예약하고, 테이프 백업을 단순화하며, 백업을 더 쉽고 편리하게 만드는 데 사용할 수 있는 많은 타사 유틸리티를 제공합니다. 이러한 애플리케이션 중 다수는 클라이언트/서버 기반이며 단일 시스템 또는 네트워크에 있는 모든 컴퓨터의 백업을 자동화하는 데 사용할 수 있습니다.

인기 있는 유틸리티로는 Amanda, Bacula, rsync, duplicity 등이 있습니다.

=== 긴급 복구

정기 백업 외에도 비상 대비 계획의 일환으로 다음 단계를 수행하는 것이 좋습니다.

다음 명령 출력의 인쇄 사본을 만듭니다:

* `gpart show`
* `more /etc/fstab`
* `dmesg`

이 출력물과 설치 미디어 사본을 안전한 장소에 보관하세요. 긴급 복원이 필요한 경우, 설치 미디어로 부팅하고 `Live CD` 를 선택하여 복구 셸에 액세스합니다. 이 복구 모드에서는 시스템의 현재 상태를 확인하고 필요한 경우 디스크를 다시 포맷하고 백업에서 데이터를 복원하는 데 사용할 수 있습니다.

[NOTE]
====
FreeBSD/i386 {rel112-current}-RELEASE용 설치 미디어에는 복구 셸이 포함되어 있지 않습니다. 이 버전의 경우, 대신 ftp://ftp.FreeBSD.org/pub/FreeBSD/releases/i386/ISO-IMAGES/{rel112-current}/FreeBSD-{rel112-current}-RELEASE-i386-livefs.iso[ftp://ftp.FreeBSD.org/pub/FreeBSD/releases/i386/ISO-IMAGES/{rel112-current}/FreeBSD-{rel112-current}-RELEASE-i386-livefs.iso] 링크에서 Livefs CD 이미지를 다운로드하여 구우세요.
====

다음으로, 복구 셸과 백업을 테스트합니다. 절차를 메모합니다. 이 메모를 미디어, 출력물, 백업과 함께 보관하세요. 이러한 메모는 긴급 복구를 수행해야 하는 상황에서 백업이 실수로 파괴되는 것을 방지할 수 있습니다.

보안을 강화하려면 컴퓨터 및 디스크 드라이브와 물리적으로 멀리 떨어진 원격 위치에 최신 백업을 저장하세요.

[[disks-virtual]]
== 메모리 디스크

물리 디스크 외에도, FreeBSD는 메모리 디스크의 생성과 사용도 지원합니다. 메모리 디스크의 용도 중 하나는 ISO 파일 시스템의 콘텐츠에 액세스하기 위해 CD나 DVD로 구운 다음 CD/DVD 미디어를 마운트하는 번거로움 없이 액세스하는 것입니다.

FreeBSD에서는 man:md[4] 드라이버가 메모리 디스크에 대한 지원을 제공하는 데 사용됩니다. 이 드라이버는 [.filename]#GENERIC# 커널에 포함되어 있습니다. 사용자 정의 커널 구성 파일을 사용하는 경우 이 줄이 포함되어 있는지 확인하십시오:

[.programlisting]
....
device md
....

[[disks-mdconfig]]
=== 기존 이미지 연결 및 분리하기

기존 파일 시스템 이미지를 마운트하려면 `mdconfig` 를 사용하여 ISO 파일의 이름과 사용 가능한 단위 번호를 지정합니다. 그런 다음 해당 단위 번호를 참조하여 기존 마운트 지점에 마운트합니다. 마운트되면 ISO의 파일이 마운트 지점에 나타납니다. 이 예제에서는 메모리 장치 [.filename]#/dev/md0# 에 _diskimage.iso_ 를 첨부한 다음 해당 메모리 장치를 [.filename]#/mnt# 에 마운트합니다:

[source, shell]
....
# mdconfig -f diskimage.iso -u 0
# mount -t cd9660 /dev/md0 /mnt
....

ISO 포맷을 마운트하기 위해 `-t cd9660` 이 사용되었음을 알 수 있습니다. 유닛 번호를 `-u` 로 지정하지 않으면 `mdconfig` 는 사용하지 않는 메모리 장치를 자동으로 할당하고 할당된 유닛의 이름(예: [.filename]#md4# )을 출력합니다. 이 명령과 옵션에 대한 자세한 내용은 man:mdconfig[8]을 참조하세요.

메모리 디스크를 더 이상 사용하지 않을 때는 해당 리소스를 시스템에 다시 릴리스해야 합니다. 먼저 파일 시스템을 마운트 해제하고 `mdconfig` 를 사용하여 시스템에서 디스크를 분리하고 해당 리소스를 해제합니다. 이 예제를 계속 진행합니다:

[source, shell]
....
# umount /mnt
# mdconfig -d -u 0
....

메모리 디스크가 아직 시스템에 연결되어 있는지 확인하려면 `mdconfig -l` 을 입력합니다.

[[disks-md-freebsd5]]
=== 파일 또는 메모리-백업 메모리 디스크 만들기

FreeBSD는 하드 디스크 또는 메모리 영역에서 사용할 스토리지를 할당하는 메모리 디스크도 지원합니다. 첫 번째 방법을 일반적으로 파일-백업 파일 시스템이라고 하고 두 번째 방법을 메모리-백업 파일 시스템이라고 합니다. 두 가지 유형 모두 `mdconfig` 를 사용하여 만들 수 있습니다.

새 메모리-백업 파일 시스템을 만들려면 `swap` 유형과 만들 메모리 디스크의 크기를 지정합니다. 그런 다음 메모리 디스크를 파일 시스템으로 포맷하고 평소와 같이 마운트합니다. 이 예에서는 유닛 `1` 에 5M 메모리 디스크를 생성합니다. 그런 다음 해당 메모리 디스크를 UFS 파일 시스템으로 포맷한 후 마운트합니다:

[source, shell]
....
# mdconfig -a -t swap -s 5m -u 1
# newfs -U md1
/dev/md1: 5.0MB (10240 sectors) block size 16384, fragment size 2048
        using 4 cylinder groups of 1.27MB, 81 blks, 192 inodes.
        with soft updates
super-block backups (for fsck -b #) at:
 160, 2752, 5344, 7936
# mount /dev/md1 /mnt
# df /mnt
Filesystem 1K-blocks Used Avail Capacity  Mounted on
/dev/md1        4718    4  4338     0%    /mnt
....

새 파일-백업 메모리 디스크를 만들려면 먼저 사용할 디스크 영역을 할당합니다. 이 예에서는 [.filename]#newimage# 라는 이름의 빈 5MB 파일을 만듭니다:

[source, shell]
....
# dd if=/dev/zero of=newimage bs=1k count=5k
5120+0 records in
5120+0 records out
....

그런 다음 해당 파일을 메모리 디스크에 첨부하고, 메모리 디스크에 레이블을 지정하고, UFS 파일 시스템으로 포맷한 다음, 메모리 디스크를 마운트하고, 파일 백업 디스크의 크기를 확인합니다:

[source, shell]
....
# mdconfig -f newimage -u 0
# bsdlabel -w md0 auto
# newfs -U md0a
/dev/md0a: 5.0MB (10224 sectors) block size 16384, fragment size 2048
        using 4 cylinder groups of 1.25MB, 80 blks, 192 inodes.
super-block backups (for fsck -b #) at:
 160, 2720, 5280, 7840
# mount /dev/md0a /mnt
# df /mnt
Filesystem 1K-blocks Used Avail Capacity  Mounted on
/dev/md0a       4710    4  4330     0%    /mnt
....

`mdconfig` 를 사용하여 파일- 또는 메모리-백업 파일 시스템을 만들려면 몇 가지 명령이 필요합니다. FreeBSD에는 메모리 디스크를 자동으로 구성하고, UFS 파일 시스템으로 포맷한 후 마운트하는 `mdmfs` 도 함께 제공됩니다. 예를 들어, `dd` 로 _newimage_ 를 생성한 후 다음 명령 하나로 위에 표시된 `bsdlabel`, `newfs`, `mount` 명령을 실행하는 것과 동일한 결과를 얻을 수 있습니다.:

[source, shell]
....
# mdmfs -F newimage -s 5m md0 /mnt
....

대신 `mdmfs` 를 사용하여 새 메모리-기반 메모리 디스크를 만들려면 다음 명령어를 사용합니다:

[source, shell]
....
# mdmfs -s 5m md1 /mnt
....

단위 번호를 지정하지 않으면 `mdmfs` 가 사용하지 않는 메모리 장치를 자동으로 선택합니다. `mdmfs` 에 대한 자세한 내용은 man:mdmfs[8]을 참고하세요.

[[snapshots]]
== 파일 시스템 스냅샷

FreeBSD는 crossref:config[soft-updates,Soft Updates]와 함께 파일 시스템 스냅샷이라는 기능을 제공합니다.

UFS 스냅샷을 사용하면 지정된 파일 시스템의 이미지를 생성하고 이를 파일로 취급할 수 있습니다. 스냅샷 파일은 작업이 수행되는 파일 시스템에 만들어야 하며, 사용자는 파일 시스템당 20개 이하의 스냅샷을 만들 수 있습니다. 활성 스냅샷은 슈퍼블록에 기록되므로 마운트 해제 및 재마운트 작업과 시스템 재부팅 시에도 영구적으로 유지됩니다. 스냅샷이 더 이상 필요하지 않은 경우 man:rm[1]을 사용하여 제거할 수 있습니다. 스냅샷은 어떤 순서로든 제거할 수 있지만, 다른 스냅샷이 해제된 블록 중 일부를 차지할 가능성이 있으므로 사용된 공간을 모두 확보하지 못할 수도 있습니다.

변경할 수 없는 `snapshot` 파일 플래그는 스냅샷 파일을 처음 생성한 후 man:mksnap_ffs[8]에 의해 설정됩니다. man:unlink[1]는 스냅샷 파일을 제거할 수 있으므로 스냅샷 파일에 대해 예외를 만듭니다.

스냅샷은 man:mount[8]를 사용하여 만듭니다. [.filename]#/var# 파일에 [.filename]#/var/snapshot/snap# 의 스냅샷을 배치하려면 다음 명령을 사용합니다:

[source, shell]
....
# mount -u -o snapshot /var/snapshot/snap /var
....

또는 man:mksnap_ffs[8]을 사용하여 스냅샷을 생성합니다:

[source, shell]
....
# mksnap_ffs /var /var/snapshot/snap
....

man:find[1]를 사용하여 [.filename]#/var# 과 같은 파일 시스템에서 스냅샷 파일을 찾을 수 있습니다:

[source, shell]
....
# find /var -flags snapshot
....

스냅샷이 생성되면 여러가지 용도로 사용할 수 있습니다:

* 일부 관리자는 스냅샷을 CD나 테이프로 전송할 수 있기 때문에 백업 목적으로 스냅샷 파일을 사용하기도 합니다.
* 파일 시스템 무결성 검사기인 man:fsck[8]를 스냅샷에서 실행할 수 있습니다. 파일 시스템이 마운트될 때 깨끗한 상태였다고 가정하면 항상 깨끗하고 변경되지 않은 결과를 제공해야 합니다.
* man:dump[8]를 스냅샷에 실행하면 파일 시스템 및 스냅샷의 타임스탬프와 일치하는 덤프 파일이 생성됩니다. 또한 `-L` 을 사용하여 하나의 명령으로 스냅샷을 생성하고 덤프 이미지를 생성한 다음 스냅샷을 제거할 수도 있습니다.
* 스냅샷은 파일 시스템의 고정 이미지로 마운트할 수 있습니다. man:mount[8]으로 스냅샷 [.filename]#/var/snapshot/snap# 을 실행합니다:
+
[source, shell]
....
# mdconfig -a -t vnode -o readonly -f /var/snapshot/snap -u 4
# mount -r /dev/md4 /mnt
....

고정된 [.filename]#/var# 는 이제 [.filename]#/mnt# 을 통해 사용할 수 있습니다. 처음에는 모든 것이 스냅샷 생성 시와 동일한 상태로 유지됩니다. 유일한 예외는 이전 스냅샷이 길이가 0인 파일로 표시된다는 점입니다. 스냅샷을 마운트 해제하려면:

[source, shell]
....
# umount /mnt
# mdconfig -d -u 4
....

기술 문서를 포함하여 `softupdates` 및 파일 시스템 스냅샷에 대한 자세한 내용은 Marshall Kirk McKusick의 웹사이트(http://www.mckusick.com/[http://www.mckusick.com/]를 참조하세요.

[[quotas]]
== 디스크 할당량

디스크 할당량을 사용하여 사용자 또는 그룹 구성원이 파일 시스템별로 할당할 수 있는 디스크 공간의 양이나 파일 수를 제한할 수 있습니다. 이렇게 하면 한 사용자 또는 사용자 그룹이 사용 가능한 디스크 공간을 모두 소비하는 것을 방지할 수 있습니다.

이 섹션에서는 UFS 파일 시스템에 대한 디스크 할당량을 구성하는 방법에 대해 설명합니다. ZFS 파일 시스템에서 할당량을 구성하려면 crossref:zfs[zfs-zfs-quota,"Dataset, User, and Group Quotas"]을 참조하세요

=== 디스크 할당량 활성화하기

FreeBSD 커널이 디스크 할당량을 지원하는지 확인하려면:

[source, shell]
....
% sysctl kern.features.ufs_quota
kern.features.ufs_quota: 1
....

이 예에서 `1` 은 할당량 지원을 나타냅니다. 값이 대신 `0` 이면 커스텀 커널 구성 파일에 다음 줄을 추가하고 crossref:kernelconfig[kernelconfig,Configuring the FreeBSD Kernel]의 지침을 사용하여 커널을 다시 빌드합니다:

[.programlisting]
....
options QUOTA
....

다음으로, [.filename]#/etc/rc.conf# 에서 디스크 할당량을 활성화합니다:

[.programlisting]
....
quota_enable="YES"
....

일반적으로 부팅 시 각 파일 시스템의 할당량 무결성은 man:quotacheck[8]에 의해 확인됩니다. 이 프로그램은 할당량 데이터베이스의 데이터가 파일 시스템의 데이터를 올바르게 반영하는지 확인합니다. 이 과정은 시간이 오래 걸리므로 시스템 부팅에 상당한 영향을 미칩니다. 이 단계를 건너뛰려면 [.filename]#/etc/rc.con f#에 다음 변수를 추가하세요:

[.programlisting]
....
check_quotas="NO"
....

마지막으로 [.filename]#/etc/fstab# 을 편집하여 파일 시스템 단위로 디스크 할당량을 사용하도록 설정합니다. 파일 시스템에서 사용자별 할당량을 설정하려면 할당량을 사용 설정할 파일 시스템의 [.filename]#/etc/fstab# 항목에 있는 옵션 필드에 `userquota` 를 추가합니다. 예를 들어:

[.programlisting]
....
/dev/da1s2g   /home    ufs rw,userquota 1 2
....

그룹 할당량을 사용하려면 대신 `groupquota` 를 사용합니다. 사용자 할당량과 그룹 할당량을 모두 사용하려면 쉼표로 옵션을 구분합니다:

[.programlisting]
....
/dev/da1s2g    /home    ufs rw,userquota,groupquota 1 2
....

기본적으로 할당량 파일은 파일 시스템의 루트 디렉터리에 [.filename]#quota.user# 및 [.filename]#quota.group# 으로 저장됩니다. 자세한 내용은 man:fstab[5]을 참조하세요. 할당량 파일의 대체 위치를 지정하는 것은 권장하지 않습니다.

구성을 완료하고 시스템을 재부팅하면 [.filename]#/etc/rc# 가 자동으로 적절한 명령을 실행하여 [.filename]#/etc/fstab# 에서 활성화된 모든 할당량에 대한 초기 할당량 파일을 생성합니다.

일반적인 작업 과정에서는 man:quotacheck[8], man:quotaon[8] 또는 man:quotaoff[8]를 수동으로 실행할 필요가 없습니다. 그러나 설명서 페이지를 읽고 작동법을 숙지해야 합니다.

=== 할당량 한도 설정하기

할당량이 활성화되어 있는지 확인하려면 다음을 실행합니다:

[source, shell]
....
# quota -v
....

할당량이 활성화된 각 파일 시스템에 대해 디스크 사용량과 현재 할당량 제한에 대한 한 줄 요약이 있어야 합니다.

이제 시스템에 `edquota` 을 사용하여 할당량 한도를 지정할 준비가 되었습니다.

사용자 또는 그룹이 할당할 수 있는 디스크 공간의 양과 생성할 수 있는 파일 수에 제한을 적용하는 데는 여러 가지 옵션이 있습니다. 디스크 공간(블록 할당량), 파일 수(이노드 할당량) 또는 이 두 가지의 조합을 기준으로 할당을 제한할 수 있습니다. 각 제한은 하드 제한과 소프트 제한의 두 가지 범주로 더 세분화됩니다.

하드 제한은 초과할 수 없습니다. 사용자가 하드 제한에 도달하면 해당 사용자는 해당 파일 시스템에 더 이상 할당할 수 없습니다. 예를 들어, 사용자가 파일 시스템의 하드 제한이 500KB이고 현재 490KB를 사용 중인 경우, 사용자는 추가로 10KB만 할당할 수 있습니다. 추가로 11바이트를 할당하려고 시도하면 실패합니다.

소프트 제한은 유예 기간이라고 하는 제한된 시간 동안 초과할 수 있으며, 이 기간은 기본적으로 1주일입니다. 사용자가 유예 기간보다 더 오래 한도를 초과하면 소프트 제한이 하드 제한으로 바뀌고 더 이상 할당이 허용되지 않습니다. 사용자가 소프트 제한 아래로 다시 떨어지면 유예 기간이 초기화됩니다.

다음 예에서는 `test` 계정의 할당량을 편집하고 있습니다. `edquota` 가 호출되면 할당량 한도를 편집하기 위해 `EDITOR` 로 지정된 편집기가 열립니다. 기본 편집기는 vi로 설정되어 있습니다.

[source, shell]
....
# edquota -u test
Quotas for user test:
/usr: kbytes in use: 65, limits (soft = 50, hard = 75)
        inodes in use: 7, limits (soft = 50, hard = 60)
/usr/var: kbytes in use: 0, limits (soft = 50, hard = 75)
        inodes in use: 0, limits (soft = 50, hard = 60)
....

할당량이 활성화된 각 파일 시스템에는 일반적으로 두 줄이 표시됩니다. 한 줄은 블록 제한을 나타내고 다른 줄은 이노드 제한을 나타냅니다. 할당량 제한을 수정하려면 값을 변경합니다. 예를 들어 [.filename]#/usr# 의 블록 제한을 소프트 제한 `500` 과 하드 제한 `600` 으로 높이려면 해당 줄의 값을 다음과 같이 변경합니다:

[.programlisting]
....
/usr: kbytes in use: 65, limits (soft = 500, hard = 600)
....

새로운 할당량 제한은 편집기를 종료할 때 적용됩니다.

여러 사용자에 대해 할당량 제한을 설정하는 것이 바람직한 경우도 있습니다. 먼저 원하는 할당량 제한을 사용자에게 할당하기 위해 이 작업을 수행할 수 있습니다. 그런 다음 `-p` 를 사용하여 해당 할당량을 지정된 범위의 사용자 ID(UID)에 복제합니다. 다음 명령은 UID `10,000` 부터 `19,999` 까지 해당 할당량 제한을 복제합니다:

[source, shell]
....
# edquota -p test 10000-19999
....

자세한 내용은 man:edquota[8]를 참조하세요.

=== 할당량 제한 및 디스크 사용량 확인하기

개별 사용자 또는 그룹 할당량과 디스크 사용량을 확인하려면 man:quota[1]를 사용하세요. 사용자는 자신의 할당량과 자신이 속한 그룹의 할당량만 확인할 수 있습니다. 수퍼유저만 모든 사용자 및 그룹 할당량을 볼 수 있습니다. 할당량이 활성화된 파일 시스템에 대한 모든 할당량 및 디스크 사용량 요약을 보려면 man:repquota[8]를 사용합니다.

일반적으로 사용자가 디스크 공간을 사용하지 않은 파일 시스템은, 사용자가 해당 파일 시스템에 할당된 할당량 제한이 있더라도 `quota` 출력에 표시되지 않습니다. 이러한 파일 시스템을 표시하려면 `-v` 를 사용하십시오. 다음은 두 파일 시스템에 할당량 제한이 있는 사용자에 대해 `quota -v` 의 샘플 출력입니다.

[.programlisting]
....
Disk quotas for user test (uid 1002):
     Filesystem  usage    quota   limit   grace   files   quota   limit   grace
           /usr      65*     50      75   5days       7      50      60
       /usr/var       0      50      75               0      50      60
....

이 예에서는 사용자가 현재 [.filename]#/usr# 에서 소프트 한도인 50KB를 15KB 초과하고 있으며 유예 기간이 5일 남았습니다. 별표 `*` 는 사용자가 현재 할당량 제한을 초과했음을 나타냅니다.

=== NFS를 통한 할당량

할당량은 NFS 서버의 할당량 하위 시스템에 의해 적용됩니다. man:rpc.rquotad[8] 데몬은 NFS 클라이언트의 `quota` 가 할당량 정보를 사용할 수 있도록 하여 해당 시스템의 사용자가 할당량 통계를 볼 수 있도록 합니다.

NFS 서버에서 [.filename]*/etc/inetd.conf* 의 줄에서 `+#+` 를 제거하여 `rpc.rquotad` 를 활성화합니다:

[.programlisting]
....
rquotad/1      dgram rpc/udp wait root /usr/libexec/rpc.rquotad rpc.rquotad
....

그런 다음 `inetd` 를 다시 시작합니다:

[source, shell]
....
# service inetd restart
....

[[disks-encrypting]]
== 디스크 파티션 암호화하기

FreeBSD는 무단 데이터 액세스에 대한 탁월한 온라인 보호 기능을 제공합니다. 파일 권한과 crossref:mac[mac,Mandatory Access Control](MAC)은 운영 체제가 활성화되고 컴퓨터 전원이 켜져 있는 동안 권한이 없는 사용자가 데이터에 액세스하는 것을 방지합니다. 그러나 공격자가 컴퓨터에 물리적으로 액세스할 수 있고 컴퓨터의 하드 드라이브를 다른 시스템으로 이동하여 데이터를 복사하고 분석할 수 있는 경우 운영 체제에서 시행하는 권한은 무의미합니다.

공격자가 하드 드라이브나 전원이 꺼진 컴퓨터를 어떻게 점유했는지에 상관없이, FreeBSD에 내장된 GEOM 기반 암호화 서브 시스템은 상당한 자원을 가진 강력한 공격자로부터 컴퓨터의 파일 시스템에 있는 데이터를 보호할 수 있습니다. 개별 파일을 암호화하는 암호화 방법과 달리, 내장된 `gbde` 및 `geli` 유틸리티를 사용하여 전체 파일 시스템을 투명하게 암호화할 수 있습니다. 클리어 텍스트는 하드 드라이브의 플래터에 절대 닿지 않습니다.

이 장에서는 FreeBSD에서 암호화된 파일 시스템을 만드는 방법을 설명합니다. 먼저 `gbde` 를 사용하여 프로세스를 보여준 다음 `geli` 를 사용하여 동일한 예제를 보여줍니다.

=== gbde를 사용한 디스크 암호화

man:gbde[4] 기능의 목적은 공격자가 _콜드_ 저장 장치의 콘텐츠에 액세스하는 것을 어렵게 만드는 것입니다. 그러나 컴퓨터가 실행 중이고 저장 장치가 활성 상태로 연결되어 있거나 공격자가 유효한 암호에 액세스할 수 있는 경우 저장 장치의 콘텐츠에 대한 보호 기능을 제공하지 않습니다. 따라서 시스템이 실행되는 동안 물리적 보안을 제공하고 암호화 메커니즘에서 사용하는 암호 구문을 보호하는 것이 중요합니다.

이 기능은 각 디스크 섹터에 저장된 데이터를 보호하기 위해 몇 가지 배리어를 제공합니다. CBC 모드에서 128비트 AES를 사용하여 디스크 섹터의 내용을 암호화합니다. 디스크의 각 섹터는 서로 다른 AES 키로 암호화됩니다. 사용자가 제공한 암호문에서 섹터 키가 파생되는 방법을 포함하여 암호화 설계에 대한 자세한 내용은 man:gbde[4]를 참조하세요.

FreeBSD는 이 명령으로 로드할 수 있는 gbde용 커널 모듈을 제공합니다:

[source, shell]
....
# kldload geom_bde
....

사용자 정의 커널 구성 파일을 사용하는 경우 다음 내용이 포함되어 있는지 확인하세요:

`options GEOM_BDE`

다음 예제에서는 [.filename]#/private# 으로 마운트할 단일 암호화된 파티션을 보관할 새 하드 드라이브를 시스템에 추가하는 방법을 보여 줍니다.

[.procedure]
.절차: gbde로 파티션 암호화하기
. 새 하드 드라이브 추가
+
<<disks-adding>> 에 설명된 대로 시스템에 새 드라이브를 설치합니다. 이 예제에서는 [.filename]#/dev/ad4s1c# 로 새 하드 드라이브 파티션이 추가되었으며 [.filename]#/dev/ad0s1*# 은 기존 표준 FreeBSD 파티션을 나타냅니다.
+
[source, shell]
....
# ls /dev/ad*
/dev/ad0        /dev/ad0s1b     /dev/ad0s1e     /dev/ad4s1
/dev/ad0s1      /dev/ad0s1c     /dev/ad0s1f     /dev/ad4s1c
/dev/ad0s1a     /dev/ad0s1d     /dev/ad4
....

. `gbde` 잠금 파일을 보관할 디렉터리 생성
+
[source, shell]
....
# mkdir /etc/gbde
....
+
gbde 잠금 파일에는 gbde가 암호화된 파티션에 액세스하는 데 필요한 정보가 포함되어 있습니다. 잠금 파일에 액세스할 수 없으면 소프트웨어에서 지원하지 않는 상당한 수동 개입 없이는 암호화된 파티션에 포함된 데이터의 암호를 해독할 수 없습니다. 암호화된 각 파티션은 별도의 잠금 파일을 사용합니다.
. `gbde` 파티션 초기화
+
gbde 파티션을 사용하려면 먼저 초기화해야 합니다. 이 초기화는 한 번만 수행하면 됩니다. 템플릿에서 다양한 구성 옵션을 설정하기 위해 기본 편집기를 엽니다. UFS 파일 시스템과 함께 사용하려면 sector_size를 2048로 설정합니다:
+
[source, shell]
....
# gbde init /dev/ad4s1c -i -L /etc/gbde/ad4s1c.lock
# $FreeBSD: src/sbin/gbde/template.txt,v 1.1.36.1 2009/08/03 08:13:06 kensmith Exp $
#
# Sector size is the smallest unit of data which can be read or written.
# Making it too small decreases performance and decreases available space.
# Making it too large may prevent filesystems from working.  512 is the
# minimum and always safe.  For UFS, use the fragment size
#
sector_size	=	2048
[...]
....
+
편집 내용이 저장되면 데이터 보안에 사용되는 비밀번호를 입력하라는 메시지가 두 번 표시됩니다. 암호는 두 번 모두 동일해야 합니다. 데이터를 보호하는 gbde의 기능은 전적으로 암호의 품질에 달려 있습니다. 기억하기 쉬운 보안 암호를 선택하는 방법에 대한 팁은 http://world.std.com/\~reinhold/diceware.html[http://world.std.com/~reinhold/diceware.htm]을 참조하세요.
+
이 초기화는 gbde 파티션에 대한 잠금 파일을 생성합니다. 이 예제에서는 [.filename]#/etc/gbde/ad4s1c.lock# 으로 저장됩니다. 잠금 파일은 ".lock"으로 끝나야 [.filename]#/etc/rc.d/gbde# 시작 스크립트에서 올바르게 감지할 수 있습니다.
+
[CAUTION]
====
잠금 파일은 암호화된 파티션의 콘텐츠와 함께 _반드시_ 백업해야 합니다. 잠금 파일이 없으면 정당한 소유자도 암호화된 파티션의 데이터에 액세스할 수 없습니다.
====

. 암호화된 파티션을 커널에 연결
+
[source, shell]
....
# gbde attach /dev/ad4s1c -l /etc/gbde/ad4s1c.lock
....
+
이 명령은 암호화된 파티션을 초기화할 때 선택한 암호를 입력하라는 메시지를 표시합니다. 암호화된 새 장치가 [.filename]#/dev# 에 [.filename]#/dev/device_name.bde# 로 표시됩니다:
+
[source, shell]
....
# ls /dev/ad*
/dev/ad0        /dev/ad0s1b     /dev/ad0s1e     /dev/ad4s1
/dev/ad0s1      /dev/ad0s1c     /dev/ad0s1f     /dev/ad4s1c
/dev/ad0s1a     /dev/ad0s1d     /dev/ad4        /dev/ad4s1c.bde
....

. 암호화된 장치에 파일 시스템 생성
+
암호화된 디바이스가 커널에 연결되면 디바이스에 파일 시스템을 만들 수 있습니다. 이 예에서는 소프트 업데이트가 활성화된 UFS 파일 시스템을 생성합니다. 확장자가 [.filename]#*.bde# 인 파티션을 지정해야 합니다:
+
[source, shell]
....
# newfs -U /dev/ad4s1c.bde
....

. 암호화된 파티션 마운트
+
마운트 지점을 생성하고 암호화된 파일 시스템을 마운트합니다:
+
[source, shell]
....
# mkdir /private
# mount /dev/ad4s1c.bde /private
....

. 암호화된 파일 시스템을 사용할 수 있는지 확인
+
이제 암호화된 파일 시스템이 표시되고 사용할 수 있습니다:
+
[source, shell]
....
% df -H
Filesystem        Size   Used  Avail Capacity  Mounted on
/dev/ad0s1a      1037M    72M   883M     8%    /
/devfs            1.0K   1.0K     0B   100%    /dev
/dev/ad0s1f       8.1G    55K   7.5G     0%    /home
/dev/ad0s1e      1037M   1.1M   953M     0%    /tmp
/dev/ad0s1d       6.1G   1.9G   3.7G    35%    /usr
/dev/ad4s1c.bde   150G   4.1K   138G     0%    /private
....

부팅할 때마다 암호화된 파일 시스템을 커널에 수동으로 다시 연결하고 오류를 확인한 후 마운트해야 파일 시스템을 사용할 수 있습니다. 이러한 단계를 구성하려면 [.filename]#/etc/rc.conf# 에 다음 줄을 추가합니다:

[.programlisting]
....
gbde_autoattach_all="YES"
gbde_devices="ad4s1c"
gbde_lockdir="/etc/gbde"
....

이를 위해서는 부팅 시 콘솔에서 암호 구문을 입력해야 합니다. 올바른 암호 구문을 입력하면 암호화된 파티션이 자동으로 마운트됩니다. 추가 gbde 부팅 옵션을 사용할 수 있으며 man:rc.conf[5]에 나열되어 있습니다.

[NOTE]
====
sysinstall은 gbde-암호화 장치와 호환되지 않습니다. 모든 [.filename]#*.bde# 디바이스를 커널에서 분리한 후 sysinstall을 시작해야 하며, 그렇지 않으면 디바이스를 처음 검색하는 동안 충돌이 발생합니다. 예제에서 사용된 암호화된 장치를 분리하려면 다음 명령을 사용합니다:

[source, shell]
....
# gbde detach /dev/ad4s1c
....
====

[[disks-encrypting-geli]]
=== `geli` 를 사용한 디스크 암호화

`geli` 를 사용하면 대체 암호화 GEOM 클래스를 사용할 수 있습니다. 이 제어 유틸리티는 몇 가지 기능을 추가하고 암호화 작업을 수행하기 위해 다른 체계를 사용합니다. 다음과 같은 기능을 제공합니다:

* man:crypto[9] 프레임워크를 활용하고 암호화 하드웨어를 사용할 수 있는 경우 자동으로 사용합니다.
* AES, 블로우피시, 3DES 등 여러 암호화 알고리즘을 지원합니다.
* 루트 파티션을 암호화하도록 허용합니다. 암호화된 루트 파티션에 액세스하는 데 사용되는 암호는 시스템 부팅 중에 요청됩니다.
* 두 개의 독립적인 키를 사용할 수 있습니다.
* 간단한 섹터 간 암호화를 수행하기 때문에 빠릅니다.
* 마스터 키의 백업 및 복원을 허용합니다. 사용자가 키를 파기하더라도 백업에서 키를 복원하여 데이터에 액세스할 수 있습니다.
* 스왑 파티션 및 임시 파일 시스템에 유용한 임의의 일회용 키로 디스크를 연결할 수 있습니다.

더 많은 기능과 사용 예제는 man:geli[8]에서 확인할 수 있습니다.

다음 예에서는 [.filename]#/private# 아래에 마운트된 암호화된 공급자의 마스터 키의 일부로 사용되는 키 파일을 생성하는 방법을 설명합니다. 키 파일은 마스터 키를 암호화하는 데 사용되는 임의의 데이터를 제공합니다. 마스터 키는 또한 암호로 보호됩니다. 공급자의 섹터 크기는 4kB입니다. 이 예에서는 `geli` 공급자에 연결하고, 파일 시스템을 생성하고, 마운트하고, 작업하고, 마지막으로 분리하는 방법을 설명합니다.

[.procedure]
.절차: `geli` 로 파티션 암호화하기
. `geli` 지원 로드
+
`geli` 에 대한 지원은 로드 가능한 커널 모듈로 제공됩니다. 부팅 시 모듈을 자동으로 로드하도록 시스템을 구성하려면 [.filename]#/boot/loader.conf# 에 다음 줄을 추가합니다:
+
[.programlisting]
....
geom_eli_load="YES"
....
+
지금 커널 모듈을 로드하려면:
+
[source, shell]
....
# kldload geom_eli
....
+
커스텀 커널의 경우 커널 구성 파일에 다음 줄이 포함되어 있는지 확인하세요:
+
[.programlisting]
....
options GEOM_ELI
device crypto
....

. 마스터 키 생성
+
다음 명령은 모든 데이터를 암호화할 마스터 키를 생성합니다. 이 키는 절대 변경할 수 없습니다. 이 키를 직접 사용하는 대신 하나 이상의 사용자 키로 암호화됩니다. 사용자 키는 파일에서 임의의 바이트, [.filename]#/root/da2.key# 및/또는 암호 구문(선택 사항)의 조합으로 구성됩니다. 이 경우 키 파일의 데이터 소스는 [.filename]#/dev/random# 입니다. 이 명령은 또한 성능 향상을 위해 공급자( [.filename]#/dev/da2.eli# )의 섹터 크기를 4kB로 구성합니다:
+
[source, shell]
....
# dd if=/dev/random of=/root/da2.key bs=64 count=1
# geli init -K /root/da2.key -s 4096 /dev/da2
Enter new passphrase:
Reenter new passphrase:
....
+
마스터키를 보호하는 두 가지 방법 중 하나를 단독으로 사용할 수 있으므로 비밀번호와 키 파일을 모두 사용해야 하는 것은 아닙니다.
+
키 파일을 "-"로 지정하면 표준 입력이 사용됩니다. 예를 들어, 이 명령은 3개의 키 파일을 생성합니다:
+
[source, shell]
....
# cat keyfile1 keyfile2 keyfile3 | geli init -K - /dev/da2
....

. 생성된 키로 공급자를 연결
+
공급자를 연결하려면 키 파일, 디스크 이름 및 암호를 지정합니다:
+
[source, shell]
....
# geli attach -k /root/da2.key /dev/da2
Enter passphrase:
....
+
이렇게 하면 확장자가 [.filename]#.eli# 인 새 장치가 만들어집니다:
+
[source, shell]
....
# ls /dev/da2*
/dev/da2  /dev/da2.eli
....

. 새 파일 시스템 생성
+
다음으로, UFS 파일 시스템으로 장치를 포맷하고 기존 마운트 지점에 마운트합니다:
+
[source, shell]
....
# dd if=/dev/random of=/dev/da2.eli bs=1m
# newfs /dev/da2.eli
# mount /dev/da2.eli /private
....
+
이제 암호화된 파일 시스템을 사용할 수 있습니다:
+
[source, shell]
....
# df -H
Filesystem     Size   Used  Avail Capacity  Mounted on
/dev/ad0s1a    248M    89M   139M    38%    /
/devfs         1.0K   1.0K     0B   100%    /dev
/dev/ad0s1f    7.7G   2.3G   4.9G    32%    /usr
/dev/ad0s1d    989M   1.5M   909M     0%    /tmp
/dev/ad0s1e    3.9G   1.3G   2.3G    35%    /var
/dev/da2.eli   150G   4.1K   138G     0%    /private
....

암호화된 파티션에 대한 작업이 완료되고 [.filename]#/private# 파티션이 더 이상 필요하지 않게 되면, 커널에서 `geli` 암호화된 파티션을 마운트 해제하고 분리하여 장치를 콜드 스토리지에 넣는 것이 현명합니다:

[source, shell]
....
# umount /private
# geli detach da2.eli
....

부팅 시 `geli` 로 암호화된 디바이스의 마운팅을 간소화하기 위해 [.filename]#rc.d# 스크립트가 제공됩니다. 이 예제에서는 [.filename]#/etc/rc.conf# 에 다음 줄을 추가합니다:

[.programlisting]
....
geli_devices="da2"
geli_da2_flags="-k /root/da2.key"
....

이렇게 하면 [.filename]#/dev/da2# 의 마스터 키가 [.filename]#/root/da2.key# 인 `geli` 공급자로 구성됩니다. 시스템이 종료되기 전에 커널에서 프로바이더가 자동으로 분리됩니다. 시작 프로세스 중에 스크립트는 공급자를 연결하기 전에 암호를 입력하라는 메시지를 표시합니다. 비밀번호 프롬프트 전후에 다른 커널 메시지가 표시될 수도 있습니다. 부팅 프로세스가 멈추는 것 같으면 다른 메시지 중에서 비밀번호 프롬프트가 있는지 주의 깊게 살펴보세요. 올바른 암호를 입력하면 공급자가 연결됩니다. 그런 다음 파일 시스템이 마운트되며, 일반적으로 [.filename]#/etc/fstab# 의 항목에 의해 마운트됩니다. 부팅 시 마운트하도록 파일 시스템을 구성하는 방법에 대한 지침은 crossref:basics[mount-unmount,“Mounting and Unmounting File Systems”]를 참조하세요.

[[swap-encrypting]]
== 스왑 암호화하기

디스크 파티션 암호화와 마찬가지로 스왑 공간 암호화는 중요한 정보를 보호하는 데 사용됩니다. 비밀번호를 다루는 애플리케이션을 생각해 보세요. 이러한 암호가 물리적 메모리에 남아 있는 한, 암호는 디스크에 기록되지 않으며 재부팅 후 지워집니다. 그러나 FreeBSD가 메모리 페이지를 여유 공간으로 스왑하기 시작하면 암호가 암호화되지 않은 상태로 디스크에 기록될 수 있습니다. 스왑 공간을 암호화하는 것이 이 시나리오에 대한 해결책이 될 수 있습니다.

이 섹션에서는 man:gbde[8] 또는 man:geli[8] 암호화를 사용하여 암호화된 스왑 파티션을 구성하는 방법을 설명합니다. 여기서는 [.filename]#/dev/ada0s1b# 이 스왑 파티션이라고 가정합니다.

=== 암호화된 스왑 구성하기

스왑 파티션은 기본적으로 암호화되지 않으므로 계속하기 전에 중요한 데이터를 모두 지워야 합니다. 현재 스왑 파티션을 임의의 가비지로 덮어쓰려면 다음 명령을 실행하세요:

[source, shell]
....
# dd if=/dev/random of=/dev/ada0s1b bs=1m
....

man:gbde[8]를 사용하여 스왑 파티션을 암호화하려면 [.filename]#/etc/fstab# 의 스왑 줄에 접미사 '.bde' 를 추가합니다:

[.programlisting]
....
# Device		Mountpoint	FStype	Options		Dump	Pass#
/dev/ada0s1b.bde	none		swap	sw		0	0
....

대신 man:geli[8]를 사용하여 스왑 파티션을 암호화하려면 `.eli` 접미사를 사용합니다:

[.programlisting]
....
# Device		Mountpoint	FStype	Options		Dump	Pass#
/dev/ada0s1b.eli	none		swap	sw		0	0
....

기본적으로 man:geli[8]는 키 길이가 128비트인 AES 알고리즘을 사용합니다. 보통은 기본 설정으로 충분합니다. 원하는 경우 [.filename]#/etc/fstab# 의 옵션 필드에서 이러한 기본값을 변경할 수 있습니다. 가능한 플래그는 다음과 같습니다:

aalgo::
암호화된 데이터가 변조되지 않았는지 확인하는 데 사용되는 데이터 무결성 검증 알고리즘입니다. 지원되는 알고리즘 목록은 man:geli[8]를 참조하세요.

ealgo::
데이터를 보호하는 데 사용되는 암호화 알고리즘입니다. 지원되는 알고리즘 목록은 man:geli[8]를 참조하세요.

keylen::
암호화 알고리즘에 사용되는 키의 길이입니다. 각 암호화 알고리즘에서 지원하는 키 길이는 man:geli[8]를 참조하세요.

sectorsize::
블록의 크기는 데이터가 암호화되기 전에 분할되는 크기입니다. 섹터 크기가 클수록 스토리지 오버헤드가 증가하지만 성능이 향상됩니다. 권장 크기는 4096바이트입니다.

이 예에서는 키 길이가 128비트이고 섹터 크기가 4KB인 Blowfish 알고리즘을 사용하여 암호화된 스왑 파티션을 구성합니다:

[.programlisting]
....
# Device		Mountpoint	FStype	Options				Dump	Pass#
/dev/ada0s1b.eli	none		swap	sw,ealgo=blowfish,keylen=128,sectorsize=4096	0	0
....

=== 암호화된 스왑 확인

시스템이 재부팅되면 `swapinfo` 를 사용하여 암호화된 스왑이 제대로 작동하는지 확인할 수 있습니다.

man:gbde[8]가 사용 중인 경우:

[source, shell]
....
% swapinfo
Device          1K-blocks     Used    Avail Capacity
/dev/ada0s1b.bde   542720        0   542720     0
....

man:geli[8]가 사용 중인 경우:

[source, shell]
....
% swapinfo
Device          1K-blocks     Used    Avail Capacity
/dev/ada0s1b.eli   542720        0   542720     0
....

[[disks-hast]]
== 고가용성 스토리지(HAST)

고가용성은 중요한 비즈니스 애플리케이션의 주요 요구 사항 중 하나이며, 고가용성 스토리지는 이러한 환경에서 핵심 구성 요소입니다. FreeBSD의 고가용성 스토리지(HAST) 프레임워크는 물리적으로 분리된 여러 머신에 동일한 데이터를 TCP/IP 네트워크로 연결하여 투명하게 저장할 수 있습니다. HAST는 네트워크 기반 RAID1(미러)로 이해할 수 있으며, GNU/Linux(R) 플랫폼에서 사용되는 DRBD(R) 스토리지 시스템과 유사합니다. CARP와 같은 FreeBSD의 다른 고가용성 기능과 결합하면 하드웨어 장애에 강한 고가용성 스토리지 클러스터를 구축할 수 있습니다.

다음은 HAST의 주요 기능입니다:

* 로컬 하드 드라이브의 I/O 오류를 마스킹하는 데 사용할 수 있습니다.
* 파일 시스템에 구애받지 않으므로 FreeBSD에서 지원하는 모든 파일 시스템에서 작동합니다.
* 노드의 다운타임 동안 수정된 블록만 동기화되므로 효율적이고 빠르게 재동기화할 수 있습니다.
* 이미 배포된 환경에서 여분의 중복성을 추가하는 데 사용할 수 있습니다.
* CARP, Heartbeat 또는 기타 도구와 함께 사용하면 견고하고 내구성 있는 스토리지 시스템을 구축할 수 있습니다.

이 섹션을 읽고 나면 여러분은:

* HAST가 무엇인지, 어떻게 작동하는지, 어떤 기능을 제공하는지.
* FreeBSD에서 HAST를 설정하고 사용하는 방법.
* 강력한 스토리지 시스템을 구축하기 위해 CARP와 man:devd[8]를 통합하는 방법.

이 섹션을 읽기 전에 다음을 알아야 합니다:

* UNIX(R) 및 FreeBSD 기본 사항을 이해합니다(crossref:basics[basics,FreeBSD Basics]).
* 네트워크 인터페이스 및 기타 핵심 FreeBSD 하위 시스템을 구성하는 방법을 알아야 합니다(crossref:config[config-tuning,Configuration and Tuning]).
* FreeBSD 네트워킹을 잘 이해해야 합니다(crossref:partiv[network-communication,"Network Communication"]).

HAST 프로젝트는 http://www.omc.net/[http://www.omc.net/] 및 http://www.transip.nl/[http://www.transip.nl/]의 지원으로 FreeBSD 재단의 후원을 받았습니다.

=== HAST 작업

HAST는 두 개의 물리적 머신, 즉 _primary_ 노드와 _secondary_ 노드 간에 동기식 블록 레벨 복제를 제공합니다. 이 두 시스템을 함께 클러스터라고 합니다.

HAST는 일차-이차 구성으로 작동하기 때문에, 클러스터 노드 중 하나만 언제든지 활성화됩니다. _액티브_ 라고도 하는 일차 노드는 HAST 관리 장치에 대한 모든 I/O 요청을 처리하는 노드입니다. 이차 노드는 일차 노드에서 자동으로 동기화됩니다.

HAST 시스템의 물리적 구성 요소는 일차 노드의 로컬 디스크와 원격의 이차 노드에 있는 디스크입니다.

HAST는 블록 수준에서 동기적으로 작동하므로 파일 시스템과 애플리케이션에 투명합니다. HAST는 다른 도구나 애플리케이션에서 사용할 수 있도록 [.filename]#/dev/hast/# 에 일반 GEOM 공급자를 제공합니다. HAST 제공 장치와 원시 디스크 또는 파티션을 사용하는 것 사이에는 차이가 없습니다.

각각의 쓰기, 삭제 또는 플러시 작업은 TCP/IP를 통해 로컬 디스크와 원격 디스크 모두에 전송됩니다. 로컬 디스크가 최신 상태가 아니거나 I/O 오류가 발생하지 않는 한, 각 읽기 작업은 로컬 디스크에서 제공됩니다. 문제가 발생한 경우, 읽기 작업은 이차 노드로 전송됩니다.

HAST는 빠른 장애 복구를 제공하기 위해 노력합니다. 따라서 노드 중단 후 동기화 시간을 줄이는 것이 중요합니다. 빠른 동기화를 제공하기 위해 HAST는 더티 익스텐트의 온디스크 비트맵을 관리하고 초기 동기화를 제외한 정기 동기화 중에만 동기화합니다.

동기화를 처리하는 방법에는 여러 가지가 있습니다. HAST는 다양한 동기화 방법을 처리하기 위해 여러 가지 복제 모드를 구현합니다:

* _memsync_ : 이 모드는 로컬 쓰기 작업이 완료되고 원격 노드가 데이터 도착을 확인하지만 실제로 데이터를 저장하기 전일 때 쓰기 작업이 완료된 것으로 보고합니다. 원격 노드(이차 노드)의 데이터는 승인 전송 후 바로 저장됩니다. 이 모드는 지연 시간을 줄이기 위한 것이지만 여전히 우수한 안정성을 제공합니다. 이 모드가 기본값입니다.
* _fullsync_ : 이 모드는 로컬 쓰기와 원격 쓰기가 모두 완료되면 쓰기 작업이 완료된 것으로 보고합니다. 가장 안전하면서도 가장 느린 복제 모드입니다.
* _async_ : 이 모드는 로컬 쓰기가 완료되면 쓰기 작업이 완료된 것으로 보고합니다. 가장 빠르지만 가장 위험한 복제 모드입니다. 다른 모드를 사용하기에는 지연 시간이 너무 길어 멀리 떨어진 노드로 복제할 때만 사용해야 합니다.

=== HAST 구성

HAST 프레임워크는 여러 구성 요소로 이루어져 있습니다:

* 데이터 동기화를 제공하는 man:hastd[8] 데몬입니다. 이 데몬이 시작되면 `geom_gate.ko` 를 자동으로 로드합니다.
* 사용자 공간 관리 유틸리티, man:hastctl[8].
* man:hast.conf[5] 구성 파일. 이 파일은 hastd를 시작하기 전에 존재해야 합니다.

커널에 `GEOM_GATE` 지원을 정적으로 빌드하고 싶은 사용자는 커스텀 커널 구성 파일에 이 줄을 추가한 다음 crossref:kernelconfig[kernelconfig,Configuring the FreeBSD Kernel]의 지침에 따라 커널을 다시 빌드해야 합니다:

[.programlisting]
....
options	GEOM_GATE
....

다음 예제는 HAST를 사용하여 두 노드 간 데이터를 복제하는 일차-이차 작업에서 두 노드를 구성하는 방법을 설명합니다. 노드는 `172.16.0.1` 의 IP 주소를 가진 `hasta` 와 `172.16.0.2` 의 IP 주소를 가진 `hastb` 로 불립니다. 두 노드 모두 HAST 작동을 위해 동일한 크기의 전용 하드 드라이브 [.filename]#/dev/ad6# 을 갖게 됩니다. HAST 풀은 리소스 또는 [.filename]#/dev/hast/# 의 GEOM 제공자라고도 하며, `test` 라고 합니다.

HAST의 구성은 [.filename]#/etc/hast.conf# 를 사용하여 수행됩니다. 이 파일은 두 노드에서 동일해야 합니다. 가장 간단한 구성은:

[.programlisting]
....
resource test {
	on hasta {
		local /dev/ad6
		remote 172.16.0.2
	}
	on hastb {
		local /dev/ad6
		remote 172.16.0.1
	}
}
....

고급 구성은 man:hast.conf[5]를 참조하세요.

[TIP]
====
호스트가 [.filename]#/etc/hosts# 또는 로컬 DNS에 정의되어 있고 확인 가능한 경우 `remote` 문에 호스트 이름을 사용할 수도 있습니다.
====

구성파일이 두 노드에 모두 존재하면 HAST 풀을 생성할 수 있습니다. 두 노드에서 다음 명령을 실행하여 초기 메타데이터를 로컬 디스크에 배치하고 man:hastd[8]를 시작합니다:

[source, shell]
....
# hastctl create test
# service hastd onestart
....

[NOTE]
====
기존 파일 시스템과 함께 GEOM 공급자를 사용하거나 기존 저장소를 HAST 관리 풀로 변환하는 것은 _불가능_ 합니다. 이 절차는 일부 메타데이터를 제공자에 저장해야 하며 기존 제공자에는 필요한 공간이 충분하지 않을 것입니다.
====

HAST 노드의 `일차` 또는 `이차` 역할은 관리자 또는 Heartbeat와 같은 소프트웨어가 man:hastctl[8]을 사용하여 선택합니다. 일차 노드인 `hasta` 에서 이 명령을 실행합니다:

[source, shell]
....
# hastctl role primary test
....

이차 노드인 `hastb` 에서 이 명령을 실행합니다:

[source, shell]
....
# hastctl role secondary test
....

각 노드에서 `hastctl` 을 실행하여 결과를 확인합니다:

[source, shell]
....
# hastctl status test
....

출력에서 `status` 줄을 확인하세요. `degraded` 이라고 표시되면 구성 파일에 문제가 있는 것입니다. 각 노드에 `complete` 라고 표시되어야 하며, 이는 노드 간 동기화가 시작되었음을 의미합니다. `hastctl status` 가 0바이트의 `dirty` 익스텐트를 보고하면 동기화가 완료됩니다.

다음 단계는 GEOM 공급자에 파일 시스템을 생성하고 마운트하는 것입니다. 이 작업은 '일차' 노드에서 수행해야 합니다. 파일 시스템을 생성하는 데에는 하드 드라이브의 크기에 따라 몇 분 정도 걸릴 수 있습니다. 이 예제에서는 [.filename]#/dev/hast/test# 에 UFS 파일 시스템을 생성합니다:

[source, shell]
....
# newfs -U /dev/hast/test
# mkdir /hast/test
# mount /dev/hast/test /hast/test
....

HAST 프레임워크가 올바르게 구성되면, 마지막 단계는 시스템 부팅 중에 HAST가 자동으로 시작되도록 하는 것입니다. 이 줄을 [.filename]#/etc/rc.conf# 에 추가합니다:

[.programlisting]
....
hastd_enable="YES"
....

==== 장애 조치 구성

이 예제의 목표는 특정 노드의 장애에 견딜 수 있는 강력한 스토리지 시스템을 구축하는 것입니다. 일차 노드에 장애가 발생하면 이차 노드가 원활하게 인계받아 파일 시스템을 확인하고 마운트하여 단 하나의 비트 데이터도 놓치지 않고 계속 작업할 수 있습니다.

이 작업을 수행하기 위해 공통 주소 중복 프로토콜(Common Address Redundancy Protocol, CARP)을 사용하여 IP 계층에서 자동 장애조치를 제공합니다. CARP를 사용하면 동일한 네트워크 세그먼트에 있는 여러 호스트가 하나의 IP 주소를 공유할 수 있습니다. crossref:advanced-networking[carp,“Common Address Redundancy Protocol (CARP)”] 문서에 나와 있는 설명서에 따라 클러스터의 두 노드에서 CARP를 설정합니다. 이 예제에서 각 노드는 자체 관리 IP 주소와 _172.16.0.254_ 의 공유 IP 주소를 갖습니다. 클러스터의 일차 HAST 노드는 일차 CARP 노드여야 합니다.

이제 이전 섹션에서 생성한 HAST 풀을 네트워크의 다른 호스트로 내보낼 준비가 되었습니다. 공유 IP 주소 _172.16.0.254_ 를 사용하여 NFS 또는 Samba를 통해 내보내면 됩니다. 아직 해결되지 않은 유일한 문제는 기본 노드에 장애가 발생할 경우 자동 장애조치입니다.

CARP 인터페이스가 올라가거나 내려가는 경우, FreeBSD 운영체제는 man:devd[8] 이벤트를 생성하여 CARP 인터페이스의 상태 변화를 관찰할 수 있게 합니다. CARP 인터페이스의 상태 변경은 노드 중 하나가 실패했거나 다시 온라인 상태가 되었음을 나타냅니다. 이러한 상태 변경 이벤트를 통해 HAST 장애 조치를 자동으로 처리하는 스크립트를 실행할 수 있습니다.

CARP 인터페이스의 상태 변경을 포착하려면 각 노드의 [.filename]#/etc/devd.conf# 에 다음 구성을 추가하세요:

[.programlisting]
....
notify 30 {
	match "system" "IFNET";
	match "subsystem" "carp0";
	match "type" "LINK_UP";
	action "/usr/local/sbin/carp-hast-switch primary";
};

notify 30 {
	match "system" "IFNET";
	match "subsystem" "carp0";
	match "type" "LINK_DOWN";
	action "/usr/local/sbin/carp-hast-switch secondary";
};
....

[NOTE]
====
시스템이 FreeBSD 10 이상을 실행하는 경우 [.filename]#carp0# 을 CARP로 구성된 인터페이스의 이름으로 바꿉니다.
====

두 노드 모두에서 man:devd[8]를 재시작하여 새 구성을 적용합니다:

[source, shell]
....
# service devd restart
....

지정된 인터페이스 상태가 위 또는 아래로 이동하여 변경되면 시스템은 알림을 생성하여 man:devd[8] 서브시스템이 지정된 자동 장애조치 스크립트인 [.filename]#/usr/local/sbin/carp-hast-switch# 를 실행할 수 있도록 합니다. 이 구성에 대한 자세한 설명은 man:devd.conf[5]를 참조하세요.

다음은 자동화된 장애 조치 스크립트의 예입니다:

[.programlisting]
....
#!/bin/sh

# Original script by Freddie Cash <fjwcash@gmail.com>
# Modified by Michael W. Lucas <mwlucas@BlackHelicopters.org>
# and Viktor Petersson <vpetersson@wireload.net>

# The names of the HAST resources, as listed in /etc/hast.conf
resources="test"

# delay in mounting HAST resource after becoming primary
# make your best guess
delay=3

# logging
log="local0.debug"
name="carp-hast"

# end of user configurable stuff

case "$1" in
	primary)
		logger -p $log -t $name "Switching to primary provider for ${resources}."
		sleep ${delay}

		# Wait for any "hastd secondary" processes to stop
		for disk in ${resources}; do
			while $( pgrep -lf "hastd: ${disk} \(secondary\)" > /dev/null 2>&1 ); do
				sleep 1
			done

			# Switch role for each disk
			hastctl role primary ${disk}
			if [ $? -ne 0 ]; then
				logger -p $log -t $name "Unable to change role to primary for resource ${disk}."
				exit 1
			fi
		done

		# Wait for the /dev/hast/* devices to appear
		for disk in ${resources}; do
			for I in $( jot 60 ); do
				[ -c "/dev/hast/${disk}" ] && break
				sleep 0.5
			done

			if [ ! -c "/dev/hast/${disk}" ]; then
				logger -p $log -t $name "GEOM provider /dev/hast/${disk} did not appear."
				exit 1
			fi
		done

		logger -p $log -t $name "Role for HAST resources ${resources} switched to primary."

		logger -p $log -t $name "Mounting disks."
		for disk in ${resources}; do
			mkdir -p /hast/${disk}
			fsck -p -y -t ufs /dev/hast/${disk}
			mount /dev/hast/${disk} /hast/${disk}
		done

	;;

	secondary)
		logger -p $log -t $name "Switching to secondary provider for ${resources}."

		# Switch roles for the HAST resources
		for disk in ${resources}; do
			if ! mount | grep -q "^/dev/hast/${disk} on "
			then
			else
				umount -f /hast/${disk}
			fi
			sleep $delay
			hastctl role secondary ${disk} 2>&1
			if [ $? -ne 0 ]; then
				logger -p $log -t $name "Unable to switch role to secondary for resource ${disk}."
				exit 1
			fi
			logger -p $log -t $name "Role switched to secondary for resource ${disk}."
		done
	;;
esac
....

간단히 말해, 스크립트는 노드가 일차 노드가 될 때 이러한 작업을 수행합니다:

* 다른 노드에서 HAST 풀을 일차 노드(Primary)로 승격합니다.
* HAST 풀 아래의 파일 시스템을 확인합니다.
* 풀을 마운트합니다.

노드가 이차 노드(Secondary Node)가 되는 경우:

* HAST 풀을 마운트 해제합니다.
* HAST 풀을 이차 노드로 강등합니다.

[CAUTION]
====
이것은 개념 증명을 위한 예시 스크립트일 뿐입니다. 가능한 모든 시나리오를 처리하는 것은 아니며 필요한 서비스를 시작하거나 중지하는 등 어떤 방식으로든 확장하거나 변경할 수 있습니다.
====

[TIP]
====
이 예에서는 표준 UFS 파일 시스템을 사용했습니다. 복구에 필요한 시간을 줄이려면 저널이 활성화된 UFS 또는 ZFS 파일 시스템을 대신 사용할 수 있습니다.
====

추가 예시와 함께 더 자세한 정보는 http://wiki.FreeBSD.org/HAST[http://wiki.FreeBSD.org/HAST]에서 확인할 수 있습니다.

=== 문제 해결

HAST는 일반적으로 문제 없이 작동합니다. 그러나 다른 소프트웨어 제품과 마찬가지로 예상대로 작동하지 않는 경우가 있을 수 있습니다. 문제의 원인은 다양할 수 있지만, 일반적으로 클러스터의 노드 간에 시간이 동기화되어 있는지 확인하는 것이 좋습니다.

HAST 문제를 해결할 때, `hastd` 를 `-d` 로 시작하여 man:hastd[8]의 디버깅 레벨을 높여야 합니다. 이 인자는 디버깅 수준을 더 높이기 위해 여러 번 지정할 수 있습니다. 또한 `hastd` 를 포어 그라운드에서 시작하는 `-F` 를 사용하는 것도 고려하십시오.

[[disks-hast-sb]]
==== Split-brain 상태에서 복구하기

_Split-brain_ 는 클러스터의 노드가 서로 통신할 수 없고 둘 다 일차 노드로 구성되어 있을 때 발생합니다. 이 경우 두 노드 모두 데이터를 호환되지 않는 방식으로 변경할 수 있으므로 위험한 상태입니다. 이 문제는 시스템 관리자가 수동으로 수정해야 합니다.

관리자는 어느 노드에 더 중요한 변경 사항이 있는지 결정하거나 수동으로 병합을 수행해야 합니다. 그런 다음 HAST가 손상된 데이터가 있는 노드에 대해 전체 동기화를 수행하도록 합니다. 이렇게 하려면 다시 동기화해야 하는 노드에서 다음 명령을 실행합니다:

[source, shell]
....
# hastctl role init test
# hastctl create test
# hastctl role secondary test
....
